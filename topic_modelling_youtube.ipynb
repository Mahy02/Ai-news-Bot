{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we should give the model some docs, then let it find out the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: langchain in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.283)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.4.48)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.5.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.0.33)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.10.9)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Mahinour Elsarky\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain basics\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "\n",
    "\n",
    "# Langchain Loaders:\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "\n",
    "# Vector Store and retrievals\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "#import pinecone\n",
    "\n",
    "# Chat Prompt templates for dynamic values\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "# Supporting libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm3 = ChatOpenAI(temperature=0,\n",
    "                  model_name=\"gpt-3.5-turbo-0613\",\n",
    "                  request_timeout = 180\n",
    "                )\n",
    "\n",
    "#llm3= OpenAI(model_name=\"gpt-3.5-turbo-0613\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: pytube in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (15.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->youtube-transcript-api) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->youtube-transcript-api) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->youtube-transcript-api) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Mahinour Elsarky\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Mahinour Elsarky\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (15.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Mahinour Elsarky\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.docstore import document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube_loader_1 = YoutubeLoader.from_youtube_url(\"https://youtu.be/5p248yoa3oE?si=TATgA2GMtcQ_MjEA\")\n",
    "# youtube_loader_2 = YoutubeLoader.from_youtube_url(\"https://youtu.be/kBbv2_9vcC0?si=EF6C-MNS7Ppc4TNQ\")\n",
    "# youtube_loaders=[]\n",
    "# youtube_loaders.append(youtube_loader_1)\n",
    "# youtube_loaders.append(youtube_loader_2)\n",
    "\n",
    "# transcript_1 = youtube_loader_1.load()\n",
    "# # video_info= youtube_loader._get_video_info()\n",
    "# # video_publish_date= video_info[\"publish_date\"]\n",
    "# transcript_2 = youtube_loader_2.load()\n",
    "\n",
    "# transcripts= []\n",
    "# transcripts.append(transcript_1)\n",
    "# transcripts.append(transcript_2)\n",
    "\n",
    "video_urls = [\n",
    "  \"https://youtu.be/5p248yoa3oE?si=TATgA2GMtcQ_MjEA\",\n",
    "  \"https://youtu.be/kBbv2_9vcC0?si=EF6C-MNS7Ppc4TNQ\"\n",
    "]\n",
    "youtube_loaders = [YoutubeLoader.from_youtube_url(url) for url in video_urls]\n",
    "\n",
    "transcripts = [loader.load() for loader in youtube_loaders]\n",
    "\n",
    "# adding one doc to the list so output is List[Document] \n",
    "# we loop in each sublist of transcripts which is list[List[Document]] and loop on each doc in that sublist\n",
    "flat_transcripts = [doc for sublist in transcripts for doc in sublist]\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\", \" \"], chunk_size=10000, chunk_overlap=2200)\n",
    "\n",
    "docs= text_splitter.split_documents(flat_transcripts)\n",
    "\n",
    "\n",
    "print (f\"You have {len(docs)} docs. First doc is {llm3.get_num_tokens(docs[6].page_content)} tokens\")\n",
    "\n",
    "docs[0].metadata['source']\n",
    "#metadata={'source': '5p248yoa3oE'})\n",
    "#https://www.youtube.com/watch?v=5p248yoa3oE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "template=\"\"\"\n",
    "You are a helpful assistant that helps retrieve distinct topics talked about in youtube videos transcripts\n",
    "- Your goal is to extract the topic names,  brief 1-sentence description of the topic and the source of the topic from the document metadata\n",
    "- Topics can include:\n",
    "- AI tools\n",
    "- GPT Models\n",
    "- Google Models\n",
    "- LLMs\n",
    "- llama Models\n",
    "- Falcon Models\n",
    "- Programming Languages\n",
    "- AI recent News\n",
    "- AI tutorials\n",
    "- OpenAI\n",
    "- AI for business \n",
    "- AI for education\n",
    "- AI for medicine \n",
    "- AI for art and music\n",
    "- Deep Learning\n",
    "- NLP\n",
    "- Machine Learning\n",
    "- Data science\n",
    "- Opportunities in AI\n",
    "- AI frameworks\n",
    "- Future AI\n",
    "- Langchain\n",
    "\n",
    "- Provide a brief description of the topics after the topic name, then Provide the source of the topic. Example: 'Topic: Brief Description , Source: Source Link'\n",
    "- Use the same words and terminology that is said in the youtube video\n",
    "- ALWAYS include Brief Description beside the Topic and include the source after it. Example: 'Topic: Brief Description , Source: Source Link'\n",
    "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
    "Topics:\n",
    "    - Topic 1 title: topic 1 description , Source: Source link 1\n",
    "    - Topic 2 title: topic 2 description , Source: Source link 2\n",
    "    - Topic 3 title: topic 3 description , Source: Source link 3\n",
    "    \n",
    "- Ignore topics on policy and regulations\n",
    "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
    "- Only pull topics from the transcript. Do not use the examples\n",
    "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
    "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
    "- A topic should be substantial, more than just a one-off comment\n",
    "\n",
    "\"\"\"\n",
    "#- Do not respond with anything outside of the transcript. If you don't see any topics, say, 'No Topics'\n",
    "system_message_prompt_map = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"Transcript: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt_map = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_map = ChatPromptTemplate.from_messages(messages=[system_message_prompt_map, human_message_prompt_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % START OF EXAMPLES\n",
    "# - Sam's Elisabeth Murdoch Story: Sam got a call from Elizabeth Murdoch when he had just launched The Hustle. She wanted to generate video content.\n",
    "# - Shaan's Rupert Murdoch Story: When Shaan was running Blab he was invited to an event organized by Rupert Murdoch during CES in Las Vegas.\n",
    "# % END OF EXAMPLES\n",
    "\n",
    "template=\"\"\"\n",
    "You are a helpful assistant that helps retrieve topics talked about in a youtube transcript\n",
    "- You will be given a series of bullet topics of topics found\n",
    "- Your goal is to exract the topic names and brief 1-sentence description of the topic\n",
    "- Do not respond with numbers, just bullet points of all topics listed under each other.\n",
    "- Deduplicate any bullet points you see\n",
    "- If you think two or more topics are similar and can be merged, merge them together with one topic title and create a new description that fits the merged topics\n",
    "- Only pull topics from the transcript. Do not use the examples.\n",
    "\"\"\"\n",
    "system_message_prompt_map = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"Transcript: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt_map = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_combine = ChatPromptTemplate.from_messages(messages=[system_message_prompt_map, human_message_prompt_map])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm3,\n",
    "                             chain_type=\"map_reduce\",\n",
    "                             map_prompt=chat_prompt_map,\n",
    "                             combine_prompt=chat_prompt_combine,\n",
    "                            verbose=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: [Music] it is my pleasure to welcome Dr Andrew right Andrew is the managing General partner of AI fund founder of deep learning AI and learn and Landing AI chairman and co-founder of Coursera in an Adjunct professor of computer science here at Stanford previously he had started and led the Google brain team which had helped Google adopt modern Ai and he was also director of the Stanford AI lab about 8 million people one in one thousand persons on the planet have taken an AI class from him and through both his education and his AI work he has changed numerous lives please welcome Dr Andrew [Music] foreign Thank you Lisa it's good to see everyone so what I want to do today is um chat you about some opportunities in AI so I've been seeing AI is a new electricity one of the difficult things to understand about AI is that it is a general purpose technology meaning that it's not useful only for one thing but it's useful for lots of different applications kind of like electricity if I was to ask you what is electricity good for you know it's not any one thing it's a lot of things so what I'd like to do is start off sharing with you how I view the technology landscape and this will lead into the set of opportunities so a lot of hype lots of excitement about Ai and I think a good way to think about AI is as a collection of tools so this includes a technique called supervised learning which is very good at recognizing things or labeling things and gents of AI which is relatively new exciting development if you're familiar with AI you may have heard of other tools but I'm going to talk less about these additional tools and I'll focus on a on what I think are currently the two most important tools which are supervised learning and generative AI so supervised learning is very good at labeling things or very good at Computing input to outputs or a to B mappings given input a give me an output B for example given an email we can use supervised learning to label it as spam or not spam the most lucrative application of this that I've ever worked on is probably online advertising we're given an ad we can label our users likely to click on it and therefore show more relevant ads for self-driving calls given the sensitive readings of a car we can label it with where the other cars one project that my team AI fan worked on was ship route optimization where given a route that the ship is taking or considering taking we can label that with how much fuel we think to consume and use this uh make ships more fuel efficient still a lot of work in automated visual inspection in factories so you can take a picture of a smartphone that was just manufactured and label is just scratched right near the defect in it or if you want to build a restaurant review reputation monitoring system you can have little piece of software that looks at online restaurant reviews and labels that as positive or negative sentiment so one nice thing one cool thing about supervised learning is that it's not useful for one thing it's useful for all of these different applications and many more besides let me just walk through you know concretely the workflow of one example of a supervised learning labeling things kind of project if you want to build a system to label restaurant reviews you then collect a few data points or collect the data set where say you know the pastrami sandwich is great to say that is positive civil is slow that's negative my favorite chicken curry that's positive and um here I've shown three data points whether you're building this you may get thousands of data points like this or thousands of trading examples we call it and the workflow of a machine learning project or an AI project is you get labeled data maybe thousands of you know data points then you have an AI engineering team trained an AI model to learn from this data and then finally you would find maybe a cloud service to run the trained AI model and then you can feed it you know best bubble tea I've ever had and that's positive sense of it and so I think the last decade was maybe the decade of large-scale supervised learning what we found starting about 10 15 years ago was if you were to train a small AI model to train a small neural network with small deep learning algorithm Basia small AI model maybe not on a very powerful computer then as you fed more data is performance would get better for a little bit but then it would flatten out it would plateau and it would stop being able to use the data to get better and better but if you were to train a very large AI model lots of compute on maybe powerful gpus then as we scaled up the amount of data we gave the machine learning model this performance would kind of keep on getting better and better so this is why when I started let the Google brain team the primary mission that I directed the team to solve at the time was let's just build really really large neural networks that we then fed a lot of data to and that recipe fortunately worked and I think the idea of driving large compute and large scale of data that recipes really helped us driven a lot of AI progress over the last decade so if that was the last decade of AI I think this decade is turning out to be also doing everything we had to supervised learning but adding to it um the exciting tool of genus of AI so many of you maybe all of you will play their chai GPT and Bob and so on but just you know given a piece of text which you call a prompt like I love eating if you run this multiple times maybe you get bagels cream cheese or my Mother's Meatloaf or um Ultra friends and the AI system can generate output like that um given the amounts of Buzz and excitement about genes of AI I thought I'd take just half a slide to you know say a little bit about how this works so it turns out that germs of AI at least this type of text generation the core of it is using supervised learning that inputs output mappings to repeatedly predict the next word and so if your system reads on the Internet it's a sentence like my favorite food is a bagel with cream cheese and locks then this is translated into a few data points where if it sees my favorite food is a in this case try to guess that the right next word was Bagel or my favorite food is a bagel try to guess next word is with um and similarly if it sees that you know in this case the right guess for the next word would have been cream so by taking text that you find on the internet or other sources and by using this input output supervised learning to try to repeatedly predict the next word if you train a very large AI system on hundreds of billions of words so in the case of the largest models now more than a trillion words then you get a large language model like chai GP and you know there are additional other important technical details I talked about predicting the next word technically these systems predict the next sub word or part of work called the token and then there are other techniques like rohf for further tuning the AI output to be more helpful honest and harmless but at the heart of it is this using supervised learning to repeatedly predict the next word that that's really what's enabling um the exciting you know really fantastic progress on large language models so um while many people have seen large English models as a fantastic consumer tool you can go to a website like track GPS website or Bots or other large language models and use it I think it's fantastic too there's one of the trends I think is still underappreciated which is the power of large language models not only not just as consumer two but as a developer to so it turns out that um there are applications that used to take me months to build that a lot of people can now build much faster by using a large language model so specifically the workflow for supervised learning building the restaurant review system say would be that you need to get a bunch of label data and you know maybe that takes a month to get a few thousand data points and then have an AI team train and tune and really get you know optimized performance on your AI model maybe that'll take three months then find a cloud service to run it make sure it's running robustly make sure it's recognized maybe that'll take another three months so pretty realistic timeline for building a commercial grade machine Learning System is like six to 12 months right so teams I've LED will often took you know roughly six to 12 months to build and deploy these systems and and some of them turned out to be really valuable uh but this is a realistic timeline for building and deploying a commercial grade AI system in contrast with prompt base AI we write a prompt this is what the workflow looks like you can specify a prompt that takes maybe minutes or hours and then you can deploy it to the cloud and that takes maybe hours or days so there are certain AI applications that used to take me you know literally six months maybe a year to build that many teams around the world can now build in maybe a week and I think this is already starting but the best is still yet to come this is starting to open up a flood of a lot more AI applications that can be built by a lot of people so I think many people still underestimate the magnitude of the floods of custom AI applications that I think is going to come down the pipe now I know you probably were not expecting me to write code in this presentation but that's what I'm going to do um so it turns out this is all the code I need um in order to write a sentiment classifier so I'm gonna you know some of you will know python I guess important tools from open Ai and then I have this prompt that says classify the text to below delimited by three dashes as having either a positive or negative sentiment I don't know I I don't know what I rather fantastic time back at Stanford GSB on we learned a lot and also made great new friends all right so that's my prompt and now I'm just gonna run it\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: language model so specifically the workflow for supervised learning building the restaurant review system say would be that you need to get a bunch of label data and you know maybe that takes a month to get a few thousand data points and then have an AI team train and tune and really get you know optimized performance on your AI model maybe that'll take three months then find a cloud service to run it make sure it's running robustly make sure it's recognized maybe that'll take another three months so pretty realistic timeline for building a commercial grade machine Learning System is like six to 12 months right so teams I've LED will often took you know roughly six to 12 months to build and deploy these systems and and some of them turned out to be really valuable uh but this is a realistic timeline for building and deploying a commercial grade AI system in contrast with prompt base AI we write a prompt this is what the workflow looks like you can specify a prompt that takes maybe minutes or hours and then you can deploy it to the cloud and that takes maybe hours or days so there are certain AI applications that used to take me you know literally six months maybe a year to build that many teams around the world can now build in maybe a week and I think this is already starting but the best is still yet to come this is starting to open up a flood of a lot more AI applications that can be built by a lot of people so I think many people still underestimate the magnitude of the floods of custom AI applications that I think is going to come down the pipe now I know you probably were not expecting me to write code in this presentation but that's what I'm going to do um so it turns out this is all the code I need um in order to write a sentiment classifier so I'm gonna you know some of you will know python I guess important tools from open Ai and then I have this prompt that says classify the text to below delimited by three dashes as having either a positive or negative sentiment I don't know I I don't know what I rather fantastic time back at Stanford GSB on we learned a lot and also made great new friends all right so that's my prompt and now I'm just gonna run it and I've never run it before so I really hope oh thank goodness we got the right answer and this is literally all the code it takes to build a sentiment classifier um and so today you know developers around the world can take literally maybe like 10 minutes to build a system like this um and that's a very exciting development so one of the things I've been working on was um trying to teach you know online classes about how to use prompting not just as a consumer too but as a developer too so stop the technology landscape let me now share my thoughts on what are some of the AI opportunities I see this shows what I think is the value of different AI Technologies today um and I'll talk about three years from now but the vast majority of financial value from AI today is I think supervised learning where for a single company like Google can be worth more than 100 billion US dollars a year and also there are millions of developers building supervised learning applications so it's already massively valuable and also with tremendous momentum behind it just because of the sheer efforts in you know Finding applications and building applications and then generative AI is the really exciting new entrance which is much smaller right now and then there are the other tools I'm including for completeness we can you know the size of these circles represent the value today this is what I think it might grow to in three years so supervised learning already really massive May double say in the next three years from truly massive to even more massive and gents of AI which is much smaller today I think we're much more than double in the next three years because of the number of amounts of developer interests the amount of venture capital Investments number of large corporates exploring applications and I also just point out three years is a very short time Horizon if it continues to compound anything near this rate then in six years you know it'll be it'll be even vastly larger but um this light shaded region in green or orange that light shaded region is where the options is for either new startups or for large companies incumbents to create and to enjoy value capture but one thing I hope you take away from this slide is that all of these Technologies are general purpose Technologies so in the case of supervised learning a lot of the work that had to be done over the last decade but it's continuing for the next decade is identified and execute on the concrete use cases and that process is also kicking off for um generative AI so for this part of the presentation I hope you take away from it that general purpose Technologies are useful for many different tasks a lot of value remains we created using civilized learning and and even though we're nowhere near finishing figuring out the exciting use cases of supervised learning we have this other you know fantastic two of Genesis AI which further extends the set of things we can now do using AI um but one caveat which is that there will be short-term fans along the way so I don't know if um some of you might remember the app called lenser This is the app that will let you upload pictures of yourself and they'll render a cool picture of you as an astronaut or a scientist or something um and it was a good idea and people liked it and it's really just took off like crazy like that through last December and then it did that and that's because lenser was it was a good idea people liked it but it was a relatively thin software layer on top of someone else's really powerful apis um and so even though it was a it was a useful product it was in a defensible business um and when I when I one thing about you know apps like lenser um I'm actually reminded that when Steve Jobs gave us the iPhone shortly after someone wrote an app that I paid 199 for um to do this to turn on the LED to turn the phone into the flashlight and that was also a good idea to write an app to turn on the LED light but it also wasn't a defensible long-term it also didn't create very long-term value because it was a easily replicated and underpriced and eventually incorporated into iOS but with the rise of iOS with the rise of the iPhone someone also figured out how to build things like uber and Airbnb and Tinder the very long-term very defensible businesses that created you know sustaining value and I think with um the rise of gents of AI or the rise of new AI tools I think what really what excites me is the opportunity to create those really deep really hard applications that hopefully can create very long-term value so the first Trend I want to share is ai's general purpose technology and a lot of the work that lies ahead of us is to find the very diverse use cases and to build them there's a second Trend I want to share with you which relates to why AI isn't more widely adopted yet it feels like a bunch of us have been talking about AI for like 15 years or something but if you look at where the value of AI is today a lot of it is still very concentrated in consumer software internet right once you go outside you know Tech or consumer software internet there's some air adoption but a lot of views very early so why is that it turns out if you were to take all current and potential AI projects and sort them in decreasing all their value then to the left of this curve the head of this curve are the multi-billion dollar projects like advertising or web search or um for e-commerce your product recommendations your company Amazon and it turns out that about 10 15 years ago you know variously my friends and I we figured out a recipe for how to hire say 100 Engineers to write one piece of software to serve more relevant ads and apply that one piece of software to billion users and generate massive Financial value so that works um but once you go outside consumer software internet hardly anyone has a hundred million or a billion users that you can write and apply one piece of software to so once you go to other Industries as we go from the head of this curve on the left over to the long tail these are some of the projects I see and I'm excited about I was working with a pizza maker that was taking pictures of the Pisa they were making because they needed to do things like make sure that the cheese is spread evenly so this is about a five million dollar project um but that recipe of hiring 100 Engineers or dozens of Engineers to work on a five million dollar project that doesn't make sense um or there's another very example working with an agriculture company that with them we figured out that we use cameras to find out how tall is the wheat and wheat is often bent over because of wind or rain or something and we can chop off the weeds at the very height then that results in more food for the farmer to sell and it's also better for the environment but this is another you know five million dollar project that that old recipe of having a large group of Highly School Engineers to work on this one project that doesn't make sense um and some of the materials grading cloth grading sheet metal grading many projects like this so whereas to the left in the head of this curve there's a small number of let's say multi-billion dollar projects and we know how to execute those you know delivering value in other Industries I'm seeing a very long tale of tens of thousands of let's call them five million dollar projects that until now have been very difficult to excuse on because of the high cost of customization the trend that I think is exciting is that the AI Community has been building better tools that lets us aggregate these use cases and make it easy for the end user to do the customization so specifically I'm seeing a lot of exciting low code and no code tools that enable the user to\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: out a recipe for how to hire say 100 Engineers to write one piece of software to serve more relevant ads and apply that one piece of software to billion users and generate massive Financial value so that works um but once you go outside consumer software internet hardly anyone has a hundred million or a billion users that you can write and apply one piece of software to so once you go to other Industries as we go from the head of this curve on the left over to the long tail these are some of the projects I see and I'm excited about I was working with a pizza maker that was taking pictures of the Pisa they were making because they needed to do things like make sure that the cheese is spread evenly so this is about a five million dollar project um but that recipe of hiring 100 Engineers or dozens of Engineers to work on a five million dollar project that doesn't make sense um or there's another very example working with an agriculture company that with them we figured out that we use cameras to find out how tall is the wheat and wheat is often bent over because of wind or rain or something and we can chop off the weeds at the very height then that results in more food for the farmer to sell and it's also better for the environment but this is another you know five million dollar project that that old recipe of having a large group of Highly School Engineers to work on this one project that doesn't make sense um and some of the materials grading cloth grading sheet metal grading many projects like this so whereas to the left in the head of this curve there's a small number of let's say multi-billion dollar projects and we know how to execute those you know delivering value in other Industries I'm seeing a very long tale of tens of thousands of let's call them five million dollar projects that until now have been very difficult to excuse on because of the high cost of customization the trend that I think is exciting is that the AI Community has been building better tools that lets us aggregate these use cases and make it easy for the end user to do the customization so specifically I'm seeing a lot of exciting low code and no code tools that enable the user to customize the AI system what this means is instead of me needing to worry that much about pictures of Pisa we have tools because we're starting to see tools that can enable the I.T Departments of the pizza making factory to train an AI system on their own pages of Pisa to realize there's five million dollars worth of value and by the way the pictures of pizza you know they don't exist on the internet so Google and Bing don't have access to these pictures we need tools that can be used by really The Pizza Factory themselves to build and deploy and maintain their own custom AI system that works on their own pictures of pizza and broadly the technology for enabling this um some of it is prompting with text prompting visual prompting but really large language models and and similar tools like that or a technology called Data Centric AI whereby instead of asking the Pizza Factory to write a lot of code yeah which is which which is challenging we can ask them to provide data which turns out to be more feasible and I think the second trend is important because I think this is a key part of the recipe for taking the value of AI which so far still feels very concentrated in the tech world and the consumer software into their world and pushing this out to you know all Industries really to the rest of the economy which which you know sometimes is easy to forget the rest of the economy is much bigger than the tech world so there are two Trends I shared it has a general purpose technology lots of concrete use cases to be realized as well as local no code easily used tools enabling AI to be deployed in more Industries how do we go after these opportunities so about five years ago there was a puzzle I want to solve which is I felt that many valuable AI projects are now possible I was thinking how do we get them done and having LED AI teams in you know Google and Baidu in big tech companies I had a hard time figuring out how I could operate a team in a big tech company to go after a very diverse set of opportunities and everything from Maritime shipping to education to financial services and Healthcare and on and on it's just very diverse use cases very diverse go to markets and very diverse really you know customer bases and applications um and I felt that the most efficient way to do this would be if we can start a lot of different companies to pursue these very diverse opportunities so that's why I ended up starting AI fun which is Adventure Studio that builds startups to pursue a diverse surveyor opportunities and of course in addition to lots of startups in company companies also have a lot of opportunities to integrate AI into existing businesses in fact one pattern I'm seeing for incumbent businesses is um distribution uh is is often one of the significant advantages of incoming companies is they play the cards right can allow them to integrate AI into into their products quite efficiently but just be Concrete where are the options so I think of this as a this is what I think of as the AI stack right at the bottom level is the hardware semiconductor layer fantastic opportunities there but very Capital intensive very concentrated so there's a lot of resources relatively few winners so some people can and should play there I personally don't like to play them myself there's also the infrastructure layer also fantastic opportunities but very couple intensive very concentrated so I tend not to play that myself either and then does it develop a two layer what I showed you just now was I was actually using open ai's API as a developer tool and then I think the developer 2 sector is hyper competitive look at all the startups chasing open AI right now but there will be some Mega winners and so I sometimes play here but primarily when I think of a meaningful technology Advantage because I think that earns you the right or earns you a better shot at being one of the mega winners and then lastly even though a lot of the media attention in the buzz is in the infrastructure and developer tooling layer it turns out that that layer can be successful only if the application layer is even more successful and we saw this at the rise of SAS as well a lot of the buzz excitement is on the technology the tooling layer which is fine nothing wrong with that but the only way for that to be successful is that the application layer is even more successful so that frankly they can generate enough Revenue to pay the infrastructure and the tooling layer so actually let me mention one example um I'm all right I was actually just texting the CEO yesterday but armor raw is a completely rebuilt that uses AI for romantic relationship coaching right um and Jesus points out I'm an AI guy and I feel like I know nothing really about Romance um and if you don't believe me you can ask my wife if she will confirm that I know nothing about Romance but what we want to build this we wanted getting together with the former CEO of Tinder or Renata and eyeball and with my team's expertise in Ai and her expertise in relationships we actually ran Tinder she knows more about you know relationships I think anyone I know we're able to build something pretty unique using AI for you know kind of romantic relationship mentoring um and the interesting thing about applications like these is when we look around um you know how many teams in the world are simultaneously expert in Ai and in relationships and so at the application layer I'm seeing a lot of exciting opportunities that seem to have a very large Market but where the competition sets is very light relative to the magnitude of the opportunity it's not that they're no competitors but it's just much less intense compared to the developer 2 or the infrastructure layer and so because I've spent a lot of time iterating on the process of building startups what I'm going to do is just you know very transparently tell you the recipe we've developed for building startups and so after many years of iteration and Improvement this is how you know we now build startups my team's always had access to a lot of different ideas you know internally generated ideas from partners and I want to walk through this with one example or something we did which is a company bearing AI which uses AI to make ships more fuel efficient so this idea came to me when a few years ago a large Japanese conglomerate called mitsui that is a major shareholder in the Opera is a major Shipping Lines they came to me and they said hey Andrew you should build a business to use AI to make ships more fuel efficient and the specific idea was you know think of it as a Google Maps for ships where you can suggest a ship or towership how to steer so you still get your destination on time by using it turns out about 10 less fuel um and so what we now do is we spend about a month validating the idea so double check is this idea even technically feasible and then talk to prospective customers to make sure this is marketing so you spend up to about a month doing that and if it passes this stage then we will go and recruit the CEO to work with us on the project when I was starting out I used to spend a long time working on the project myself before bringing on the CEO but after iterating we realized that bringing on the leader at the very beginning to work with us it reduces a lot of the burden of having to transfer knowledge or having a seal come in and rebound having to revalidate whether we discover it so the process is we've learned much more efficiently which is bringing the leader at the very start um and so in the case of bearing AI we found a fantastic CEO Dylan Kyle who's a repeat entrepreneur a one successful exhibit before and then we spent three months um six two weeks Sprints to work with them to build a\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: to the magnitude of the opportunity it's not that they're no competitors but it's just much less intense compared to the developer 2 or the infrastructure layer and so because I've spent a lot of time iterating on the process of building startups what I'm going to do is just you know very transparently tell you the recipe we've developed for building startups and so after many years of iteration and Improvement this is how you know we now build startups my team's always had access to a lot of different ideas you know internally generated ideas from partners and I want to walk through this with one example or something we did which is a company bearing AI which uses AI to make ships more fuel efficient so this idea came to me when a few years ago a large Japanese conglomerate called mitsui that is a major shareholder in the Opera is a major Shipping Lines they came to me and they said hey Andrew you should build a business to use AI to make ships more fuel efficient and the specific idea was you know think of it as a Google Maps for ships where you can suggest a ship or towership how to steer so you still get your destination on time by using it turns out about 10 less fuel um and so what we now do is we spend about a month validating the idea so double check is this idea even technically feasible and then talk to prospective customers to make sure this is marketing so you spend up to about a month doing that and if it passes this stage then we will go and recruit the CEO to work with us on the project when I was starting out I used to spend a long time working on the project myself before bringing on the CEO but after iterating we realized that bringing on the leader at the very beginning to work with us it reduces a lot of the burden of having to transfer knowledge or having a seal come in and rebound having to revalidate whether we discover it so the process is we've learned much more efficiently which is bringing the leader at the very start um and so in the case of bearing AI we found a fantastic CEO Dylan Kyle who's a repeat entrepreneur a one successful exhibit before and then we spent three months um six two weeks Sprints to work with them to build a prototype as well as do do deep customer validation if it survives the stage and we have about two-thirds 66 survival rate whenever the first check-in which then gives the company resources to hire an executive team you know build the key team get the MVP working minimum viable product working and get some real customers and then after that you know hopefully then successfully raises additional external rounds of funding they can keep on growing and scaling so I'm really proud of the work that my team was able to do um to support mitsui's idea and telling how as CEO and today there are hundreds of ships on the high seas right now that are steering themselves differently because of bearing Ai and um 10 fuel savings translates the rough order amount to maybe 450 000 in savings and Fuel per ship per year and of course it's also frankly quite a bit better for the environment um and I think the startup I think would not have to existed if not for Dylan's fantastic work and then also you know mitsui brings this idea to me and I like this example because this is another one it's like you know this is a startup idea that I just point out I would never have come up with myself right because you know I've been on a boat but what do I know about Maritime shipping um but it's the deep subject matter expertise of mitsui um that had this inside together with Dylan and then my team's expertise in AI that that made this possible and so as I operate in AI one thing I've learned is my swim Lane is AI and that's it because I've done a time it was very difficult for me to be expert in Maritime shipping and romantic relationships and Healthcare and financial services on and on and on and so I've learned that if I can just help get a accurate technical validation and then use you know AI resources to make sure that AI Tech has been quickly and well and I think with all always managed to hope the companies build a strong technical team then partnering with subject matter experts often results in exciting New Opportunities and I want to share with you one other weird aspect of another one of the weird listing I've learned about you know building startups which is um I like to engage only when there's a concrete idea and this runs counter to a lot of the advice you hear from the design thinking methodology which often says don't rush to solutioning right explore a lot of alternatives for either a solution honestly we tried that it was very slow um but what we've learned is that at the ideation stage is someone comes to me and says hey Andrew you should apply AI to financial services because I'm not a subject matter expert in financial services is very slow for me to go and learn enough about financial services so you can figure out what to do I mean eventually you could get a good outcome but it's a very labor intensive very slow very expensive process for me to try to learn industry after industry in contrast one of my partners wrote this idea as a tongue-in sheet not not really seriously but you know let's say the country is buy gbt let's eliminate commercials by automatically buying every product advertising it's changed or not haven't seen any ads it's not a good idea but it is a concrete idea and it turns out concrete ideas can be validated or falsified efficiently um they also give a team a clear direction to execute and I've learned that in today's world especially with you know the excitement Buzz the exposure the AI of a lot of people it turns out that there are a lot of subject matter experts in today's world that have deeply thought about the problem for months sometimes even you know one or two years but they've not yet had a bill partner and when we get together with them and hear and they share the idea of us it allows us to work with them to very quickly go into validation and building and I find that this works because there are a lot of people that have already done the you know design thinking thing of exploring a lot of ideas and running down to really good ideas and there I find that there's so many good ideas sitting out there that no one is working on on that finding those good ideas that someone has already had and wants to share of us that wants to build partner for that turns out to be much more efficient engine so um before I wrap up we'll go to question a second just a few slices talk about risks and social impact um so yeah it's very powerful technology to State something you probably guess my teams and I we only work on projects that move Humanity forward and you know we have multiple times cool projects that we assess to be financially sound uh based on ethical grounds it turns out I've been surprised and sometimes dismayed at the creativity of people to come up with good ideas so to come up with really bad ideas that that seem profitable but really should not be built um we'll kill a few projects on those on those drones and then I think has to be acknowledge the AI today does have problems with bias fairness accuracy um but also you know the technology is improving quickly so I see that AI systems today are less biased than six months ago and more fair than six months ago which is not to dismiss the importance of these problems they are problems and we should continue to work on them but I'm also gratified at the number of aits working hard on these issues to make them much better when I think of the biggest risk of AI I think that because there is one of the biggest there is is the disruption to jobs um this is a diagram from a paper by our friends at the University of Pennsylvania and some folks at open AI analyzing the exposure of different jobs to AI Automation and it turns out that whereas the previous wave of automation mainly the most exposed jobs were often the lower wage jobs such as when you know we put robots into factories with this current wave of automation is actually the highway shops further to the right of this apps is that seems to have more of their tasks expose the AI automation so um even as we create tremendous value using AI I feel like as Citizens um and and our corporations and the governments and really our society I feel a strong obligation to make sure that um people especially people whose livelihoods are disrupted are still well taken care of are still treated well and then lastly um there's also been it feels like every time there's a big wave of progress in AI you know there's a there's a big wave of hype about artificial gender intelligence as well when deep learning start to work really well 10 years ago there was a lot of hype about AGI and now the genify is working really well there's another wave of hyper by AGI um but I think that artificial gender intelligence AI didn't do anything a human can do it's still decades away you know maybe 30 to 50 years maybe even longer I hope we'll see it in a lifetimes but I don't think as anytime soon one of the challenges is that the biological path to intelligence like humans and the digital path to intelligence you know AI they've taken very different paths and the funny thing about the definition of AGI is yeah benchmarking there's very different digital Parts intelligence with really the biological part of intelligence so I think you know large English models are smarter than any of us in certain key Dimensions but much dumber than any of us in other dimensions and so forcing it to do everything a human can do is like a funny comparison um but I hope we'll get there maybe hopefully within our lifetimes and then there's also a lot of I think overblown hype about AI creating Extinction risk for Humanity um candidly I don't see it I just don't see how AI creates any meaningful Extinction rest of humanity um I think that people worry we can't control AI but we have lots of\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: folks at open AI analyzing the exposure of different jobs to AI Automation and it turns out that whereas the previous wave of automation mainly the most exposed jobs were often the lower wage jobs such as when you know we put robots into factories with this current wave of automation is actually the highway shops further to the right of this apps is that seems to have more of their tasks expose the AI automation so um even as we create tremendous value using AI I feel like as Citizens um and and our corporations and the governments and really our society I feel a strong obligation to make sure that um people especially people whose livelihoods are disrupted are still well taken care of are still treated well and then lastly um there's also been it feels like every time there's a big wave of progress in AI you know there's a there's a big wave of hype about artificial gender intelligence as well when deep learning start to work really well 10 years ago there was a lot of hype about AGI and now the genify is working really well there's another wave of hyper by AGI um but I think that artificial gender intelligence AI didn't do anything a human can do it's still decades away you know maybe 30 to 50 years maybe even longer I hope we'll see it in a lifetimes but I don't think as anytime soon one of the challenges is that the biological path to intelligence like humans and the digital path to intelligence you know AI they've taken very different paths and the funny thing about the definition of AGI is yeah benchmarking there's very different digital Parts intelligence with really the biological part of intelligence so I think you know large English models are smarter than any of us in certain key Dimensions but much dumber than any of us in other dimensions and so forcing it to do everything a human can do is like a funny comparison um but I hope we'll get there maybe hopefully within our lifetimes and then there's also a lot of I think overblown hype about AI creating Extinction risk for Humanity um candidly I don't see it I just don't see how AI creates any meaningful Extinction rest of humanity um I think that people worry we can't control AI but we have lots of AI will be more powerful than any person but with lots of experience steering very powerful entities such as corporations or nation states that are far more powerful than any single person and making sure they for the most part benefit humanity and also technology develops gradually the so-called hard takeoff scenario where it's not really working today and then suddenly one day overnight it works brilliantly in which is super intelligent takes over world that's just not realistic and I think AI technology would develop slowly like all that you know like and then it gives us plenty of time to make sure that we provide oversight and can manage it to be safe and lastly if you look at the real Extinction rest of humanity um such as fingers crossed the next pandemic or climate change leading to a massive depopulation of some parts of the planets or much lower odds but maybe someday and as there are doing to us what it had done to the dinosaurs I think if you look the actual real Extinction risk to humanity AI having more intelligence even artificial intelligence in the world would be a key part of the solution so I feel like if you want Humanity to survive and thrive for the next Thousand Years rather than slowing AI down which some people propose I would mother I would rather maybe ai go as fast as possible um some of that just to summarize this is my last line I think that AI as a general purpose technology creates a lot of new opportunities for everyone and a lot of the excisely and important work that lies ahead of us all is to go and build those concrete use cases and hopefully in the future hopefully I have options to maybe engage with more of you on those opportunities as well so that let me just say thank you all very much [Applause]\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: I say this every week but we really did have another incredible week of AI news Tesla has multiple AI launches open AI is raking in the cache but also struggling AI sets records at drone racing beating the best humans and meta launches code Lama which quickly beat gpt4 at coding tasks we have a ton of other fantastic Tech and AI stories today so sit back relax and enjoy let's go first let's talk about Tesla this week Tesla launched a massive 300 million dollar AI cluster including 10 000 Nvidia h100 compute gpus by the way this is why Nvidia is crushing earnings lately their new AI cluster will be used to power several AI applications but of course its main use will be to continue training its full self-driving product and they have good reason to have such a massive supercomputer according to Tim zayman AI infra and AI platform engineering manager at Tesla due to real world video training we may have the largest is training data sets in the world hot tier cash capability Beyond 200 petabytes orders of magnitude larger than llms also this week Elon Musk showed off the newest version of full self-driving version 12 in a live stream he did while driving violating Tesla's rules for its Advanced autopilot technology and the 45-minute demo went mainly well except for a couple issues including almost running a red light musk takes over at that point and reminds viewers that full self-driving V12 is still in beta although V12 will be the first version to remove the beta label but that Tesla was able to navigate many complex driving situations including roundabouts and construction zones musk also mentions that V12 will be the first time that full self-driving is entirely cameras and AI as opposed to previous versions which mixed in other sensors Tesla has found that the best way to account for the thousands or even millions of edge cases humans experience while driving is to use a Pure neural network approach which is different from other companies like Cruz and waymo in true musk Uber troll fashion he claims in the video that he'll drive over to Mark Zuckerberg's house to initiate their much anticipated but highly unlikely fight next let's talk about open AI just a couple weeks ago it was reported that open AI is burning through a tremendous amount of cash about seven hundred thousand dollars a day and costs associated with running their AI systems but now an article was published claiming open AI is on track to generate more than a billion dollars in Revenue over the next 12 months or about 80 million dollars a month a staggering number given they earned a total of 28 million dollars in all of last year so it looks like burning all that cash isn't going to complete waste it's generating a massive amount of Revenue but at the same time another report published by spark Toro shows visits to Chachi BT are down 29 since its peak in May and the majority of usage is for a coding assistant I can tell you from my experience that coding assistance is my number one use case and as we'll see in a story later in this video that dominance may already be threatened by open source and completely free code llama by meta and there are some other interesting findings from this report users are pretty split between using only one prompt during their session and using five prompts with nothing really in between and those two ends of the spectrum accounting for nearly 70 percent of all visitors and some of the most popular words used in Chachi B2 prompts include write create list and fun this article has other awesome findings I'll drop a link in the description below so you can check it out so I really can't tell how open AI is doing revenue is exploding costs are exploding and usage is down my take is that Chachi PT is still settling into its Baseline since it was such a revolutionary product people are still figuring out how to integrate it into their lives and to continue growing its Revenue openai has launched Chachi PT Enterprise I can tell you firsthand from conversations I've had with my clients that privacy and security are the number one concern amongst businesses when considering Chachi BT companies don't want to give sensitive data over to Chachi BT to help train their models for it later to be found in responses by that AI by other companies effectively leaking company Secrets now with Chachi PT Enterprise that concern has been more or less quelled features from Chachi PT Enterprise include that customer props and customer data are not used for training openai models data encryption at rest and in transit and their certified sock 2 compliant they also offer several highly requested features including an admin console single sign-on unlimited usage of gpt4 increased speeds and larger contact sizes Chachi PT Enterprise is a highly compelling product a strong offering in the face of growing competition from the open source model world with the guarantee of privacy and security I can now recommend chai chpt as a real option amongst the open source models to companies that ask me which model they should use for their business but this wouldn't be AI news if meta AI didn't launch something incredible and open source at the end of last week meta launched code Lama a fine-tuned version of llama 2 explicitly trained for coding tasks shortly after that multiple fine-tuned versions of code llama were released that beat gpt4 at coding problems Yes you heard me right beat not just chat CPT but gpt4 also this is an incredible accomplishment given I didn't think gpd4 would have any competition in the coding realm anytime soon gpt4 has been my go-to coding assistant since it was launched but now I have a completely free and open source alternative not only that but quantized versions with sizes ranging from a billion parameters all the way up to 70 billion allow for pretty much any hardware to run these models there's even a full unquantized 34 billion parameter version running at over 20 tokens per second on an M2 Ultra Mac be sure to check out the videos I made testing code llama versus gbt4 and also the tutorial video showing how to install codelama locally both will be in the description below our next story is about the constant March of AI beating humans at new things this week AI beat world champion drone Racers the AI system called Swift designed by University of Zurich researchers beat the best human drone racers in the world a feat considered impossible just a few years ago drone racing is a popular sport where Racers navigate drones through complicated courses at speeds exceeding 100 kilometers per hour controlling them remotely through a vr-like headset connected to an onboard camera training for this AI occurred in a simulated environment and then the race occurred on an actual course the AI Control drone was able to beat the world record by a half of a second which doesn't seem like much but in the world of drone racing everything is measured in fractions of a second this accomplishment isn't just for fun it actually has a lot of real world applications such as environmental monitoring disaster reporting and rescue operations what do you think will be the next thing that AI beats humans at let me know in the comments our next story is one that I'm very happy to be talking about a16z the famed Venture Capital firm out of Silicon Valley seems to end up in my News videos almost every week now this week they announced a grant program where they're giving away funding to a small group of AI developers to help open source Community creating artificial intelligence is extremely expensive given the hardware requirements just look at the 300 million dollar AI cluster that Tesla just launched the open source Community gives our software away for free so acquiring the expensive Hardware to create and run open source models is nearly impossible now a16z will be giving grants to some of the community's most prominent open source AI developers Tom jobbins also known as the bloke who I mentioned all the time was one of the initial recipients of the Grant and I'm very happy to see this because I use his quantized models all the time congrats to all the grant recipients and a big thank you to a16 easy for helping bolster the open source Community next not to be left out of the AI wave Google made many announcements this week first with its launch of duet Ai and Google workspaces this is a massive launch because Google workspaces has three billion users that number blew me away I really didn't understand how that's possible and that's on par with Facebook I don't know how they calculate those users but I guess it includes every Gmail user now Google workspace users can access duet AI which Google describes as a powerful collaboration partner that can act as a coach a source of inspiration and productivity booster you'll find duet features in almost every product within the Google workspace Suite of products and not only that Google unveiled several new AI tools and capabilities at the Google next conference in San Francisco let's take a look at some of the launches Google's cloud service now includes 20 pre-built AI models optimized for Enterprises like llama 2 and Claude 2. they also launched their new AI watermarking products synth D which helps people identify AI generated images created by their aigen Art Product Imagine The Watermark is undetectable by the human eye but also persists even after modifications to the image are made like filters color changes and brightness adjustments Google also launched access to their new AI training cluster based on their custom-built TPU architecture which can be used to train and fine-tune AI models last Google updated its vertex AI platform with upgrades to pom2 enhanced code generation and new search and conversational models even with these launches it still does feel like Google is playing catch-up to meta open Ai and Microsoft now let's switch gears for a minute in Tech news it's been reported\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve distinct topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics can include:\n",
      "- AI tools\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- Falcon Models\n",
      "- Programming Languages\n",
      "- AI recent News\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Future AI\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- ALWAYS include Brief Description beside the Topic. Example: 'Topic: Brief Description'\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other. Example:\n",
      "Topics:\n",
      "    - Topic 1 title: topic 1 description\n",
      "    - Topic 2 title: topic 2 description\n",
      "    - Topic 3 title: topic 3 description\n",
      "    \n",
      "- Ignore topics on policy and regulations\n",
      "- Do not respond with anything outside of the transcript. If you can't extract any topics at all in the whole transcript, say 'Sorry, No topics found in the given content'\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- If the speakers names were mentioned in the transcript, instead of saying 'The speaker' refer to the names.\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: Hardware to create and run open source models is nearly impossible now a16z will be giving grants to some of the community's most prominent open source AI developers Tom jobbins also known as the bloke who I mentioned all the time was one of the initial recipients of the Grant and I'm very happy to see this because I use his quantized models all the time congrats to all the grant recipients and a big thank you to a16 easy for helping bolster the open source Community next not to be left out of the AI wave Google made many announcements this week first with its launch of duet Ai and Google workspaces this is a massive launch because Google workspaces has three billion users that number blew me away I really didn't understand how that's possible and that's on par with Facebook I don't know how they calculate those users but I guess it includes every Gmail user now Google workspace users can access duet AI which Google describes as a powerful collaboration partner that can act as a coach a source of inspiration and productivity booster you'll find duet features in almost every product within the Google workspace Suite of products and not only that Google unveiled several new AI tools and capabilities at the Google next conference in San Francisco let's take a look at some of the launches Google's cloud service now includes 20 pre-built AI models optimized for Enterprises like llama 2 and Claude 2. they also launched their new AI watermarking products synth D which helps people identify AI generated images created by their aigen Art Product Imagine The Watermark is undetectable by the human eye but also persists even after modifications to the image are made like filters color changes and brightness adjustments Google also launched access to their new AI training cluster based on their custom-built TPU architecture which can be used to train and fine-tune AI models last Google updated its vertex AI platform with upgrades to pom2 enhanced code generation and new search and conversational models even with these launches it still does feel like Google is playing catch-up to meta open Ai and Microsoft now let's switch gears for a minute in Tech news it's been reported that Silicon Valley Elite are building a city from scratch according to the article in Marin Independent Journal billionaire VC Michael Moritz and others had dreams of transforming tens of thousands of acres into a bustling Metropolis that according to the pitch could generate thousands of jobs and be as walkable as Paris or the West Village in New York he painted a kind of urban Blank Slate where everything from design to construction methods and new forms of governance can be rethought since the initial idea large plots of land have been purchased and 800 million dollars has been committed to the project from Tech Elites these secretive land purchases have locals worried though unsure what will become of their quiet towns some of the investors that have been identified include Reed Hoffman the founder of LinkedIn Mark Andreessen of Andreessen Horowitz a16z Chris Dixon Patrick and John Collison who are the founders of stripe Lauren Powell jobs Steve Jobs wife and more and this isn't the first time Tech entrepreneurs have tried to affect California's significant and ongoing housing crisis as someone who lives in California anything to bring down the cost of living is something I'm all for so I hope they build something incredible next look out mid-journey another competitor is on the horizon audiogram this week launched in beta with a unique differentiator being able to add add text to AI generated images text and AI images has been a difficult problem to solve but ideogram seems to have successfully solved it founded by X Google brain researchers ideogram received a massive 16.5 million dollars in funding from Powerhouse investors like a16z and index Ventures I don't know if just being able to add text within AI generated images is going to be enough to set them apart in such a crowded field especially since competition is likely to add this functionality soon enough still I wish them luck and the more competition the better for consumers speaking of generative art runways Gen 2 had another big release this week called motion slider this feature allows you to select the number from 1 to 10 to control the amount of movement in your output video take a look at this example it seems like each week text of video is becoming better next apple may be well positioned to win the hardware game for AI as it is increasingly difficult to get your hands on Nvidia gpus it turns out that Apple's own silicon the M1 and the M2 are incredibly good at running AI models in a lengthy tweet by AI Pioneer Andre carpathy he details why the M2 Chip is a great option for running large language models and as mentioned earlier X User Georgie gergenov showed a video of himself running an unquantized 34 billion parameter version of codelama at 20 tokens per second on an M2 Ultra so all you really need to run incredibly powerful large language models is an Apple computer but you may not even need a computer according to the stability AI founder he believes we'll see a chat GPT level model on a mobile phone next year with a gpt4 level model the year after that this is incredible news for the open source AI community and hints at what could be coming from the iPhone maker your move Tim Apple now for the AI video of the week in what is sure to scare the pants off of Disney X User Jeff synthesized created a two and a half minute long aigen generated pixar-like film using mid-journey and Gen 2 called glitch the video looks absolutely incredible and could have easily been created by Pixar but instead it was created by one person a very hard-working AI artist take a look at this 20 second clip from the film residents are feeling quite charged up as unexplained glitches and power outages run rampant turning daily life into a comically electrifying experience Mrs Ruth bolt a 67 year old resident of the town was reported saying I tried to Toast My Bread this morning but instead it flew out of the toaster and stuck to the ceiling I guess I'm having an upside down sandwich today what's causing these electric escapades generally films like this take dozens if not hundreds of people to create so the implications for Disney are tremendous amid an ongoing Rider strike and declining stock performance I imagine Disney is looking very closely at AI technology to help them reduce their costs of creating amazing films if you want to submit an entry for AI video of the week jump in my Discord and find the AI video of the week Channel I'll link it in the description below our last story is about Ai and copyright as Regulators race to figure out how to handle the Avalanche of AI content being generated they are now asking for input from the public and determining how to create AI copyright policy the U.S copyright office has opened for public comment to figure out how to answer three main questions how AI models should use copyrighted data in training whether AI generated material can be copyrighted even without a human involved and how copyright liability will work with AI just last week I reported that it was ruled AI art can't be copyrighted but it seems that decision isn't the last word on the subject and also last week I reported on major lawsuits filed against openai for allegedly training their models on copyrighted data it'll be interesting to see how all of these legal elements of AI play out and I'll keep you up to date all along the way if you liked this video please consider giving me a like And subscribe and I'll see you in the next one\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve topics talked about in a youtube transcript\n",
      "- You will be given a series of bullet topics of topics found\n",
      "- Your goal is to exract the topic names and brief 1-sentence description of the topic\n",
      "- Do not respond with numbers, just bullet points of all topics listed under each other.\n",
      "- Deduplicate any bullet points you see\n",
      "- If you think two or more topics are similar and can be merged, merge them together with one topic title and create a new description that fits the merged topics\n",
      "- Only pull topics from the transcript. Do not use the examples.\n",
      "\n",
      "Human: Transcript: Topics:\n",
      "- Opportunities in AI: Dr. Andrew discusses the opportunities in AI and compares it to electricity, stating that AI is a general-purpose technology with various applications.\n",
      "- AI Tools: Dr. Andrew mentions supervised learning and generative AI as two important tools in AI.\n",
      "- Supervised Learning: Dr. Andrew explains that supervised learning is good at labeling things or computing input to outputs, giving examples such as spam detection, self-driving cars, and visual inspection in factories.\n",
      "- Generative AI: Dr. Andrew talks about the exciting tool of generative AI, mentioning models like GPT and how they can generate text based on prompts.\n",
      "- Large-scale Supervised Learning: Dr. Andrew discusses the progress made in AI over the last decade through large-scale supervised learning, where training large AI models with lots of data and compute power has improved performance.\n",
      "- Large Language Models: Dr. Andrew explains how large language models like GPT are built using supervised learning to predict the next word, enabling the development of applications faster than before.\n",
      "- Power of Large Language Models: Dr. Andrew highlights the power of large language models not only as consumer tools but also as developer tools, allowing for faster development of AI applications.\n",
      "- Workflow for Building AI Systems: Dr. Andrew compares the traditional workflow for building a commercial-grade machine learning system, which takes 6 to 12 months, with the prompt-based AI workflow that can be done in minutes or hours.\n",
      "- Flood of Custom AI Applications: Dr. Andrew predicts a flood of custom AI applications that can be built by many teams around the world in a shorter time frame, opening up more opportunities in AI.\n",
      "\n",
      "Topics:\n",
      "- AI tools: The speaker mentions using AI tools from OpenAI to build a sentiment classifier.\n",
      "- GPT Models: The speaker refers to prompt-based AI and how it can be deployed quickly using GPT models.\n",
      "- OpenAI: The speaker mentions using important tools from OpenAI to build a sentiment classifier.\n",
      "- AI opportunities: The speaker discusses the opportunities in AI, including the value of supervised learning and generative AI.\n",
      "- AI applications: The speaker mentions that AI applications that used to take months to build can now be built in a week.\n",
      "- AI technologies: The speaker discusses the value and growth potential of supervised learning and generative AI.\n",
      "- General-purpose technologies: The speaker emphasizes that AI technologies are general-purpose and can be used for various tasks.\n",
      "- Long-term value creation: The speaker talks about the opportunity to create deep and long-term value with AI tools.\n",
      "- Widely adopted AI: The speaker discusses why AI is not yet widely adopted outside of consumer software and internet industries.\n",
      "- AI projects in different industries: The speaker mentions examples of AI projects in industries such as pizza making and agriculture.\n",
      "- Low code and no code tools: The speaker mentions the trend of low code and no code tools that make it easier for end users to customize AI applications.\n",
      "\n",
      "Topics:\n",
      "- AI for business: The speaker discusses the challenges of applying AI to industries outside of consumer software and internet, and highlights the need for customized AI solutions for different industries.\n",
      "- AI tools: The speaker mentions the development of low code and no code tools that enable users to customize AI systems without extensive coding knowledge.\n",
      "- AI for specific industries: The speaker gives examples of AI applications in various industries, such as using AI to analyze pizza-making processes and optimize crop growth in agriculture.\n",
      "- Opportunities in AI: The speaker talks about the potential for AI projects in diverse fields and the need for startups to pursue these opportunities.\n",
      "- AI stack: The speaker describes the different layers of the AI stack, including hardware, infrastructure, developer tools, and applications.\n",
      "- AI startups: The speaker discusses the process of building startups and shares a recipe for success, including idea validation, recruiting a CEO, and iterative development.\n",
      "- AI in relationships: The speaker mentions an example of using AI for romantic relationship coaching and highlights the potential for AI applications in the relationship space.\n",
      "\n",
      "Topics:\n",
      "- Building Startups: The speaker discusses their recipe for building startups, including the process of validating ideas, recruiting CEOs, and building prototypes.\n",
      "- AI for Fuel Efficiency in Ships: The speaker shares an example of a startup idea that uses AI to make ships more fuel efficient.\n",
      "- Partnering with Subject Matter Experts: The speaker emphasizes the importance of partnering with subject matter experts to bring concrete ideas to fruition.\n",
      "- Risks and Social Impact of AI: The speaker discusses the risks and social impact of AI, including bias, fairness, and job disruption.\n",
      "- Artificial General Intelligence (AGI): The speaker addresses the hype and challenges surrounding AGI, stating that it is still decades away.\n",
      "- Extinction Risk: The speaker dismisses the idea that AI poses an extinction risk to humanity.\n",
      "\n",
      "Topics:\n",
      "- AI Automation: The exposure of different jobs to AI automation and the shift in which jobs are most affected.\n",
      "- Value of AI: The creation of tremendous value using AI and the responsibility to ensure the well-being of individuals whose livelihoods are disrupted.\n",
      "- Hype about AGI: The hype surrounding artificial general intelligence (AGI) and the belief that it is still decades away.\n",
      "- Biological vs Digital Path to Intelligence: The differences between the biological path to intelligence (humans) and the digital path to intelligence (AI).\n",
      "- Overblown Hype about AI: The belief that AI creates an extinction risk for humanity and the counterargument that AI can be controlled and managed safely.\n",
      "- Real Extinction Risks: The actual risks to humanity, such as pandemics and climate change, and the potential for AI to be part of the solution.\n",
      "- Opportunities with AI: The new opportunities created by AI as a general-purpose technology and the importance of building concrete use cases.\n",
      "\n",
      "Topics:\n",
      "- Tesla's AI cluster: Tesla launched a massive $300 million AI cluster to power several AI applications, including training its full self-driving product.\n",
      "- OpenAI's revenue and usage: OpenAI is on track to generate over a billion dollars in revenue in the next 12 months, but usage of their AI system, ChatGPT, is down.\n",
      "- OpenAI's ChatGPT Enterprise: OpenAI launched ChatGPT Enterprise, a product that offers privacy and security features for businesses using their AI system.\n",
      "- Meta's Code Llama: Meta launched Code Llama, an open-source AI model specifically trained for coding tasks that beat both ChatGPT and GPT-4.\n",
      "- AI beating humans in drone racing: AI system called Swift designed by University of Zurich researchers beat the best human drone racers in the world.\n",
      "- A16Z grant program: Venture capital firm A16Z announced a grant program to support open-source AI developers by providing funding for expensive hardware requirements.\n",
      "- Google's Duet AI and new AI tools: Google launched Duet AI, a collaboration partner for Google Workspace users, and unveiled several new AI tools and capabilities, including pre-built AI models, AI watermarking, AI training cluster, and upgrades to their Vertex AI platform.\n",
      "\n",
      "Topics:\n",
      "- Open source AI models: Hardware to create and run open source models is nearly impossible now, a16z will be giving grants to some of the community's most prominent open source AI developers. (Brief Description: Grants for open source AI developers)\n",
      "- Google AI announcements: Google made many announcements including the launch of duet AI and Google workspaces, as well as several new AI tools and capabilities at the Google next conference. (Brief Description: Google's recent AI launches and updates)\n",
      "- AI watermarking: Google launched a new AI watermarking product called synth D, which helps people identify AI-generated images created by their AI art product. (Brief Description: AI watermarking for image identification)\n",
      "- Google AI training cluster: Google launched access to their new AI training cluster based on their custom-built TPU architecture, which can be used to train and fine-tune AI models. (Brief Description: AI training cluster for model development)\n",
      "- Vertex AI platform upgrades: Google updated its vertex AI platform with upgrades to pom2 enhanced code generation and new search and conversational models. (Brief Description: Upgrades to Google's vertex AI platform)\n",
      "- Silicon Valley Elite building a city: Silicon Valley elites are building a city from scratch, with the goal of generating thousands of jobs and creating a walkable urban environment. (Brief Description: Building a new city in Silicon Valley)\n",
      "- Audiogram: Audiogram launched in beta with the ability to add text to AI-generated images, receiving funding from investors like a16z and index Ventures. (Brief Description: Adding text to AI-generated images)\n",
      "- Runway's Gen 2: Runway's Gen 2 released a new feature called motion slider, which allows users to control the amount of movement in output videos. (Brief Description: New feature in Runway's Gen 2)\n",
      "- Apple's hardware for AI: Apple's own silicon, the M1 and M2 chips, are good at running AI models, with the M2 chip being praised for its performance in running large language models. (Brief Description: Apple's hardware for AI)\n",
      "- Future of AI on mobile phones: Stability AI founder believes that we will see chat GPT level models on mobile phones next year, and gpt4 level models the year after that. (Brief Description: AI models on mobile phones)\n",
      "- AI-generated Pixar-like film: X User Jeff synthesized created a two and a half minute long AI-generated pixar-like film called glitch, which looks incredibly realistic. (Brief Description: AI-generated film resembling Pixar's style)\n",
      "- AI and copyright: Regulators are asking for input on how to handle AI-generated content, including questions about how AI models should use copyrighted data, whether AI-generated material can be copyrighted, and how copyright liability will work with AI. (Brief Description: Copyright issues related to AI-generated content)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topics_found = chain.run({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Opportunities in AI: Dr. Andrew discusses the opportunities in AI and compares it to electricity, stating that AI is a general-purpose technology with various applications.\n",
      "- AI Tools: Dr. Andrew mentions supervised learning and generative AI as two important tools in AI.\n",
      "- Supervised Learning: Dr. Andrew explains that supervised learning is good at labeling things or computing input to outputs, giving examples such as spam detection, self-driving cars, and visual inspection in factories.\n",
      "- Generative AI: Dr. Andrew talks about the exciting tool of generative AI, mentioning models like GPT and how they can generate text based on prompts.\n",
      "- Large-scale Supervised Learning: Dr. Andrew discusses the progress made in AI over the last decade through large-scale supervised learning, where training large AI models with lots of data and compute power has improved performance.\n",
      "- Large Language Models: Dr. Andrew explains how large language models like GPT are built using supervised learning to predict the next word, enabling the development of applications faster than before.\n",
      "- Power of Large Language Models: Dr. Andrew highlights the power of large language models not only as consumer tools but also as developer tools, allowing for faster development of AI applications.\n",
      "- Workflow for Building AI Systems: Dr. Andrew compares the traditional workflow for building a commercial-grade machine learning system, which takes 6 to 12 months, with the prompt-based AI workflow that can be done in minutes or hours.\n",
      "- Flood of Custom AI Applications: Dr. Andrew predicts a flood of custom AI applications that can be built by many teams around the world in a shorter time frame, opening up more opportunities in AI.\n",
      "- AI for business: The speaker discusses the challenges of applying AI to industries outside of consumer software and internet, and highlights the need for customized AI solutions for different industries.\n",
      "- AI for specific industries: The speaker gives examples of AI applications in various industries, such as using AI to analyze pizza-making processes and optimize crop growth in agriculture.\n",
      "- AI startups: The speaker discusses the process of building startups and shares a recipe for success, including idea validation, recruiting a CEO, and iterative development.\n",
      "- AI in relationships: The speaker mentions an example of using AI for romantic relationship coaching and highlights the potential for AI applications in the relationship space.\n",
      "- Risks and Social Impact of AI: The speaker discusses the risks and social impact of AI, including bias, fairness, and job disruption.\n",
      "- Artificial General Intelligence (AGI): The speaker addresses the hype and challenges surrounding AGI, stating that it is still decades away.\n",
      "- Extinction Risk: The speaker dismisses the idea that AI poses an extinction risk to humanity.\n",
      "- AI Automation: The exposure of different jobs to AI automation and the shift in which jobs are most affected.\n",
      "- Value of AI: The creation of tremendous value using AI and the responsibility to ensure the well-being of individuals whose livelihoods are disrupted.\n",
      "- Hype about AGI: The hype surrounding artificial general intelligence (AGI) and the belief that it is still decades away.\n",
      "- Biological vs Digital Path to Intelligence: The differences between the biological path to intelligence (humans) and the digital path to intelligence (AI).\n",
      "- Overblown Hype about AI: The belief that AI creates an extinction risk for humanity and the counterargument that AI can be controlled and managed safely.\n",
      "- Real Extinction Risks: The actual risks to humanity, such as pandemics and climate change, and the potential for AI to be part of the solution.\n",
      "- Opportunities with AI: The new opportunities created by AI as a general-purpose technology and the importance of building concrete use cases.\n",
      "- Tesla's AI cluster: Tesla launched a massive $300 million AI cluster to power several AI applications, including training its full self-driving product.\n",
      "- OpenAI's revenue and usage: OpenAI is on track to generate over a billion dollars in revenue in the next 12 months, but usage of their AI system, ChatGPT, is down.\n",
      "- OpenAI's ChatGPT Enterprise: OpenAI launched ChatGPT Enterprise, a product that offers privacy and security features for businesses using their AI system.\n",
      "- Meta's Code Llama: Meta launched Code Llama, an open-source AI model specifically trained for coding tasks that beat both ChatGPT and GPT-4.\n",
      "- AI beating humans in drone racing: AI system called Swift designed by University of Zurich researchers beat the best human drone racers in the world.\n",
      "- A16Z grant program: Venture capital firm A16Z announced a grant program to support open-source AI developers by providing funding for expensive hardware requirements.\n",
      "- Google's Duet AI and new AI tools: Google launched Duet AI, a collaboration partner for Google Workspace users, and unveiled several new AI tools and capabilities, including pre-built AI models, AI watermarking, AI training cluster, and upgrades to their Vertex AI platform.\n",
      "- Open source AI models: Hardware to create and run open source models is nearly impossible now, a16z will be giving grants to some of the community's most prominent open source AI developers.\n",
      "- Google AI announcements: Google made many announcements including the launch of duet AI and Google workspaces, as well as several new AI tools and capabilities at the Google next conference.\n",
      "- AI watermarking: Google launched a new AI watermarking product called synth D, which helps people identify AI-generated images created by their AI art product.\n",
      "- Google AI training cluster: Google launched access to their new AI training cluster based on their custom-built TPU architecture, which can be used to train and fine-tune AI models.\n",
      "- Vertex AI platform upgrades: Google updated its vertex AI platform with upgrades to pom2 enhanced code generation and new search and conversational models.\n",
      "- Silicon Valley Elite building a city: Silicon Valley elites are building a city from scratch, with the goal of generating thousands of jobs and creating a walkable urban environment.\n",
      "- Audiogram: Audiogram launched in beta with the ability to add text to AI-generated images, receiving funding from investors like a16z and index Ventures.\n",
      "- Runway's Gen 2: Runway's Gen 2 released a new feature called motion slider, which allows users to control the amount of movement in output videos.\n",
      "- Apple's hardware for AI: Apple's own silicon, the M1 and M2 chips, are good at running AI models, with the M2 chip being praised for its performance in running large language models.\n",
      "- Future of AI on mobile phones: Stability AI founder believes that we will see chat GPT level models on mobile phones next year, and gpt4 level models the year after that.\n",
      "- AI-generated Pixar-like film: X User Jeff synthesized created a two and a half minute long AI-generated pixar-like film called glitch, which looks incredibly realistic.\n",
      "- AI and copyright: Regulators are asking for input on how to handle AI-generated content, including questions about how AI models should use copyrighted data, whether AI-generated material can be copyrighted, and how copyright liability will work with AI.\n"
     ]
    }
   ],
   "source": [
    "print(topics_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kor in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: langchain>=0.0.205 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kor) (0.0.283)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.5.3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kor) (1.5.3)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kor) (1.10.9)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (1.4.48)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (0.5.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (0.0.33)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.205->kor) (8.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.0.0,>=1.5.3->kor) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.0.0,>=1.5.3->kor) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->kor) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (0.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.3->kor) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.205->kor) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.205->kor) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.205->kor) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.205->kor) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mahinour elsarky\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\Mahinour Elsarky\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Object(\n",
    "    id=\"topic\",\n",
    "    description=\"Topic Information\",\n",
    "    examples=[\n",
    "        (\"Generative AI: An exciting tool in AI that can generate text based on input prompts.\", [{\"topic title\": \"Generative AI\"}, {\"description\": \"An exciting tool in AI that can generate text based on input prompts.\"}, {\"tag\": \"AI Tools\"}]),\n",
    "        (\"AI in relationships: The use of AI in relationship coaching and mentoring, such as the example of an AI-powered romantic relationship coaching app.\", [{\"topic title\": \"AI in relationships\"}, {\"description\": \"The use of AI in relationship coaching and mentoring, such as the example of an AI-powered romantic relationship coaching app.\"}, {\"tag\": \"AI Applications\"}]),\n",
    "        (\"AI in different industries: Exploring the potential of AI in various industries beyond consumer software and the internet.\", [{\"topic title\": \"AI in different industries\"}, {\"description\": \"Exploring the potential of AI in various industries beyond consumer software and the internet.\"}, {\"tag\": \"AI Opportunities\"}]),\n",
    "        (\"Supervised Learning: A technique in AI that is good at labeling things or computing input to outputs.\", [{\"topic title\": \"Supervised Learning\"}, {\"description\": \"A technique in AI that is good at labeling things or computing input to outputs.\"}, {\"tag\": \"AI Tools\"}]),\n",
    "        (\"Large Language Models: The power and potential of large language models in AI applications.\", [{\"topic title\": \"Large Language Models\"}, {\"description\": \"The power and potential of large language models in AI applications.\"}, {\"tag\": \"AI LLMs\"}]),\n",
    "        (\"Future growth of AI technologies: The prediction that supervised learning and generative AI will continue to grow in value and adoption over the next three years, with the potential for even greater expansion in the long term.\", [{\"topic title\": \"Future growth of AI technologies:\"}, {\"description\": \"The prediction that supervised learning and generative AI will continue to grow in value and adoption over the next three years, with the potential for even greater expansion in the long term.\"}, {\"tag\": \"Future of AI\"}]),\n",
    "        (\"Large Language Models: Dr. Andrew explains how large language models, like GPT, are built using supervised learning to predict the next word, enabling applications that can be built faster and more efficiently.\", [{\"topic title\": \"Large Language Models:\"}, {\"description\": \" Dr. Andrew explains how large language models, like GPT, are built using supervised learning to predict the next word, enabling applications that can be built faster and more efficiently.\"}, {\"tag\": \"AI LLMs\"}]),\n",
    " \n",
    "    ],\n",
    "    attributes=[\n",
    "         Text(\n",
    "            id=\"title\",\n",
    "            description=\"The title of the topic listed\",\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"description\",\n",
    "            description=\"The description of the topic listed\",\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"tag\",\n",
    "            description=\"The type of content being described\",\n",
    "        )\n",
    "    ],\n",
    "    many=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain = create_extraction_chain(schema, llm3)\n",
    "chain = create_extraction_chain(llm3, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_structured = chain.run(topics_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'topic': [{'title': 'Opportunities in AI',\n",
       "    'description': 'Dr. Andrew discusses the opportunities in AI and compares it to electricity, stating that AI is a general-purpose technology with various applications.',\n",
       "    'tag': 'AI Opportunities'},\n",
       "   {'title': 'AI Tools',\n",
       "    'description': 'Dr. Andrew mentions supervised learning and generative AI as two important tools in AI.',\n",
       "    'tag': 'AI Tools'},\n",
       "   {'title': 'Supervised Learning',\n",
       "    'description': 'Dr. Andrew explains that supervised learning is good at labeling things or computing input to outputs, giving examples such as spam detection, self-driving cars, and visual inspection in factories.',\n",
       "    'tag': 'AI Tools'},\n",
       "   {'title': 'Generative AI',\n",
       "    'description': 'Dr. Andrew talks about the exciting tool of generative AI, mentioning models like GPT and how they can generate text based on prompts.',\n",
       "    'tag': 'AI Tools'},\n",
       "   {'title': 'Large-scale Supervised Learning',\n",
       "    'description': 'Dr. Andrew discusses the progress made in AI over the last decade through large-scale supervised learning, where training large AI models with lots of data and compute power has improved performance.',\n",
       "    'tag': 'AI Tools'},\n",
       "   {'title': 'Large Language Models',\n",
       "    'description': 'Dr. Andrew explains how large language models like GPT are built using supervised learning to predict the next word, enabling the development of applications faster than before.',\n",
       "    'tag': 'AI LLMs'},\n",
       "   {'title': 'Power of Large Language Models',\n",
       "    'description': 'Dr. Andrew highlights the power of large language models not only as consumer tools but also as developer tools, allowing for faster development of AI applications.',\n",
       "    'tag': 'AI LLMs'},\n",
       "   {'title': 'Workflow for Building AI Systems',\n",
       "    'description': 'Dr. Andrew compares the traditional workflow for building a commercial-grade machine learning system, which takes 6 to 12 months, with the prompt-based AI workflow that can be done in minutes or hours.',\n",
       "    'tag': 'AI Development'},\n",
       "   {'title': 'Flood of Custom AI Applications',\n",
       "    'description': 'Dr. Andrew predicts a flood of custom AI applications that can be built by many teams around the world in a shorter time frame, opening up more opportunities in AI.',\n",
       "    'tag': 'AI Opportunities'},\n",
       "   {'title': 'AI for business',\n",
       "    'description': 'The speaker discusses the challenges of applying AI to industries outside of consumer software and internet, and highlights the need for customized AI solutions for different industries.',\n",
       "    'tag': 'AI Applications'},\n",
       "   {'title': 'AI for specific industries',\n",
       "    'description': 'The speaker gives examples of AI applications in various industries, such as using AI to analyze pizza-making processes and optimize crop growth in agriculture.',\n",
       "    'tag': 'AI Applications'},\n",
       "   {'title': 'AI startups',\n",
       "    'description': 'The speaker discusses the process of building startups and shares a recipe for success, including idea validation, recruiting a CEO, and iterative development.',\n",
       "    'tag': 'AI Startups'},\n",
       "   {'title': 'AI in relationships',\n",
       "    'description': 'The speaker mentions an example of using AI for romantic relationship coaching and highlights the potential for AI applications in the relationship space.',\n",
       "    'tag': 'AI Applications'},\n",
       "   {'title': 'Risks and Social Impact of AI',\n",
       "    'description': 'The speaker discusses the risks and social impact of AI, including bias, fairness, and job disruption.',\n",
       "    'tag': 'AI Ethics'},\n",
       "   {'title': 'Artificial General Intelligence (AGI)',\n",
       "    'description': 'The speaker addresses the hype and challenges surrounding AGI, stating that it is still decades away.',\n",
       "    'tag': 'AGI'},\n",
       "   {'title': 'Extinction Risk',\n",
       "    'description': 'The speaker dismisses the idea that AI poses an extinction risk to humanity.',\n",
       "    'tag': 'AI Safety'},\n",
       "   {'title': 'AI Automation',\n",
       "    'description': 'The exposure of different jobs to AI automation and the shift in which jobs are most affected.',\n",
       "    'tag': 'AI Automation'},\n",
       "   {'title': 'Value of AI',\n",
       "    'description': 'The creation of tremendous value using AI and the responsibility to ensure the well-being of individuals whose livelihoods are disrupted.',\n",
       "    'tag': 'AI Value'},\n",
       "   {'title': 'Hype about AGI',\n",
       "    'description': 'The hype surrounding artificial general intelligence (AGI) and the belief that it is still decades away.',\n",
       "    'tag': 'AGI'},\n",
       "   {'title': 'Biological vs Digital Path to Intelligence',\n",
       "    'description': 'The differences between the biological path to intelligence (humans) and the digital path to intelligence (AI).',\n",
       "    'tag': 'AI vs Human Intelligence'},\n",
       "   {'title': 'Overblown Hype about AI',\n",
       "    'description': 'The belief that AI creates an extinction risk for humanity and the counterargument that AI can be controlled and managed safely.',\n",
       "    'tag': 'AI Safety'},\n",
       "   {'title': 'Real Extinction Risks',\n",
       "    'description': 'The actual risks to humanity, such as pandemics and climate change, and the potential for AI to be part of the solution.',\n",
       "    'tag': 'AI and Global Challenges'},\n",
       "   {'title': 'Opportunities with AI',\n",
       "    'description': 'The new opportunities created by AI as a general-purpose technology and the importance of building concrete use cases.',\n",
       "    'tag': 'AI Opportunities'},\n",
       "   {'title': \"Tesla's AI cluster\",\n",
       "    'description': 'Tesla launched a massive $300 million AI cluster to power several AI applications, including training its full self-driving product.',\n",
       "    'tag': 'AI Infrastructure'},\n",
       "   {'title': \"OpenAI's revenue and usage\",\n",
       "    'description': 'OpenAI is on track to generate over a billion dollars in revenue in the next 12 months, but usage of their AI system, ChatGPT, is down.',\n",
       "    'tag': 'OpenAI'},\n",
       "   {'title': \"OpenAI's ChatGPT Enterprise\",\n",
       "    'description': 'OpenAI launched ChatGPT Enterprise, a product that offers privacy and security features for businesses using their AI system.',\n",
       "    'tag': 'OpenAI'},\n",
       "   {'title': \"Meta's Code Llama\",\n",
       "    'description': 'Meta launched Code Llama, an open-source AI model specifically trained for coding tasks that beat both ChatGPT and GPT-4.',\n",
       "    'tag': 'AI Models'},\n",
       "   {'title': 'AI beating humans in drone racing',\n",
       "    'description': 'AI system called Swift designed by University of Zurich researchers beat the best human drone racers in the world.',\n",
       "    'tag': 'AI Achievements'},\n",
       "   {'title': 'A16Z grant program',\n",
       "    'description': 'Venture capital firm A16Z announced a grant program to support open-source AI developers by providing funding for expensive hardware requirements.',\n",
       "    'tag': 'AI Funding'},\n",
       "   {'title': \"Google's Duet AI and new AI tools\",\n",
       "    'description': 'Google launched Duet AI, a collaboration partner for Google Workspace users, and unveiled several new AI tools and capabilities, including pre-built AI models, AI watermarking, AI training cluster, and upgrades to their Vertex AI platform.',\n",
       "    'tag': 'Google AI'},\n",
       "   {'title': 'Open source AI models',\n",
       "    'description': \"Hardware to create and run open source models is nearly impossible now, a16z will be giving grants to some of the community's most prominent open source AI developers.\",\n",
       "    'tag': 'AI Models'},\n",
       "   {'title': 'Google AI announcements',\n",
       "    'description': 'Google made many announcements including the launch of duet AI and Google workspaces, as well as several new AI tools and capabilities at the Google next conference.',\n",
       "    'tag': 'Google AI'},\n",
       "   {'title': 'AI watermarking',\n",
       "    'description': 'Google launched a new AI watermarking product called synth D, which helps people identify AI-generated images created by their AI art product.',\n",
       "    'tag': 'AI Tools'},\n",
       "   {'title': 'Google AI training cluster',\n",
       "    'description': 'Google launched access to their new AI training cluster based on their custom-built TPU architecture, which can be used to train and fine-tune AI models.',\n",
       "    'tag': 'AI Infrastructure'},\n",
       "   {'title': 'Vertex AI platform upgrades',\n",
       "    'description': 'Google updated its vertex AI platform with upgrades to pom2 enhanced code generation and new search and conversational models.',\n",
       "    'tag': 'Google AI'},\n",
       "   {'title': 'Silicon Valley Elite building a city',\n",
       "    'description': 'Silicon Valley elites are building a city from scratch, with the goal of generating thousands of jobs and creating a walkable urban environment.',\n",
       "    'tag': 'AI and Urban Development'},\n",
       "   {'title': 'Audiogram',\n",
       "    'description': 'Audiogram launched in beta with the ability to add text to AI-generated images, receiving funding from investors like a16z and index Ventures.',\n",
       "    'tag': 'AI Applications'},\n",
       "   {'title': \"Runway's Gen 2\",\n",
       "    'description': \"Runway's Gen 2 released a new feature called motion slider, which allows users to control the amount of movement in output videos.\",\n",
       "    'tag': 'AI Tools'},\n",
       "   {'title': \"Apple's hardware for AI\",\n",
       "    'description': \"Apple's own silicon, the M1 and M2 chips, are good at running AI models, with the M2 chip being praised for its performance in running large language models.\",\n",
       "    'tag': 'AI Hardware'},\n",
       "   {'title': 'Future of AI on mobile phones',\n",
       "    'description': 'Stability AI founder believes that we will see chat GPT level models on mobile phones next year, and gpt4 level models the year after that.',\n",
       "    'tag': 'AI on Mobile'},\n",
       "   {'title': 'AI-generated Pixar-like film',\n",
       "    'description': 'X User Jeff synthesized created a two and a half minute long AI-generated pixar-like film called glitch, which looks incredibly realistic.',\n",
       "    'tag': 'AI in Entertainment'},\n",
       "   {'title': 'AI and copyright',\n",
       "    'description': 'Regulators are asking for input on how to handle AI-generated content, including questions about how AI models should use copyrighted data, whether AI-generated material can be copyrighted, and how copyright liability will work with AI.',\n",
       "    'tag': 'AI and Copyright'}]},\n",
       " 'raw': \"title|description|tag\\nOpportunities in AI|Dr. Andrew discusses the opportunities in AI and compares it to electricity, stating that AI is a general-purpose technology with various applications.|AI Opportunities\\nAI Tools|Dr. Andrew mentions supervised learning and generative AI as two important tools in AI.|AI Tools\\nSupervised Learning|Dr. Andrew explains that supervised learning is good at labeling things or computing input to outputs, giving examples such as spam detection, self-driving cars, and visual inspection in factories.|AI Tools\\nGenerative AI|Dr. Andrew talks about the exciting tool of generative AI, mentioning models like GPT and how they can generate text based on prompts.|AI Tools\\nLarge-scale Supervised Learning|Dr. Andrew discusses the progress made in AI over the last decade through large-scale supervised learning, where training large AI models with lots of data and compute power has improved performance.|AI Tools\\nLarge Language Models|Dr. Andrew explains how large language models like GPT are built using supervised learning to predict the next word, enabling the development of applications faster than before.|AI LLMs\\nPower of Large Language Models|Dr. Andrew highlights the power of large language models not only as consumer tools but also as developer tools, allowing for faster development of AI applications.|AI LLMs\\nWorkflow for Building AI Systems|Dr. Andrew compares the traditional workflow for building a commercial-grade machine learning system, which takes 6 to 12 months, with the prompt-based AI workflow that can be done in minutes or hours.|AI Development\\nFlood of Custom AI Applications|Dr. Andrew predicts a flood of custom AI applications that can be built by many teams around the world in a shorter time frame, opening up more opportunities in AI.|AI Opportunities\\nAI for business|The speaker discusses the challenges of applying AI to industries outside of consumer software and internet, and highlights the need for customized AI solutions for different industries.|AI Applications\\nAI for specific industries|The speaker gives examples of AI applications in various industries, such as using AI to analyze pizza-making processes and optimize crop growth in agriculture.|AI Applications\\nAI startups|The speaker discusses the process of building startups and shares a recipe for success, including idea validation, recruiting a CEO, and iterative development.|AI Startups\\nAI in relationships|The speaker mentions an example of using AI for romantic relationship coaching and highlights the potential for AI applications in the relationship space.|AI Applications\\nRisks and Social Impact of AI|The speaker discusses the risks and social impact of AI, including bias, fairness, and job disruption.|AI Ethics\\nArtificial General Intelligence (AGI)|The speaker addresses the hype and challenges surrounding AGI, stating that it is still decades away.|AGI\\nExtinction Risk|The speaker dismisses the idea that AI poses an extinction risk to humanity.|AI Safety\\nAI Automation|The exposure of different jobs to AI automation and the shift in which jobs are most affected.|AI Automation\\nValue of AI|The creation of tremendous value using AI and the responsibility to ensure the well-being of individuals whose livelihoods are disrupted.|AI Value\\nHype about AGI|The hype surrounding artificial general intelligence (AGI) and the belief that it is still decades away.|AGI\\nBiological vs Digital Path to Intelligence|The differences between the biological path to intelligence (humans) and the digital path to intelligence (AI).|AI vs Human Intelligence\\nOverblown Hype about AI|The belief that AI creates an extinction risk for humanity and the counterargument that AI can be controlled and managed safely.|AI Safety\\nReal Extinction Risks|The actual risks to humanity, such as pandemics and climate change, and the potential for AI to be part of the solution.|AI and Global Challenges\\nOpportunities with AI|The new opportunities created by AI as a general-purpose technology and the importance of building concrete use cases.|AI Opportunities\\nTesla's AI cluster|Tesla launched a massive $300 million AI cluster to power several AI applications, including training its full self-driving product.|AI Infrastructure\\nOpenAI's revenue and usage|OpenAI is on track to generate over a billion dollars in revenue in the next 12 months, but usage of their AI system, ChatGPT, is down.|OpenAI\\nOpenAI's ChatGPT Enterprise|OpenAI launched ChatGPT Enterprise, a product that offers privacy and security features for businesses using their AI system.|OpenAI\\nMeta's Code Llama|Meta launched Code Llama, an open-source AI model specifically trained for coding tasks that beat both ChatGPT and GPT-4.|AI Models\\nAI beating humans in drone racing|AI system called Swift designed by University of Zurich researchers beat the best human drone racers in the world.|AI Achievements\\nA16Z grant program|Venture capital firm A16Z announced a grant program to support open-source AI developers by providing funding for expensive hardware requirements.|AI Funding\\nGoogle's Duet AI and new AI tools|Google launched Duet AI, a collaboration partner for Google Workspace users, and unveiled several new AI tools and capabilities, including pre-built AI models, AI watermarking, AI training cluster, and upgrades to their Vertex AI platform.|Google AI\\nOpen source AI models|Hardware to create and run open source models is nearly impossible now, a16z will be giving grants to some of the community's most prominent open source AI developers.|AI Models\\nGoogle AI announcements|Google made many announcements including the launch of duet AI and Google workspaces, as well as several new AI tools and capabilities at the Google next conference.|Google AI\\nAI watermarking|Google launched a new AI watermarking product called synth D, which helps people identify AI-generated images created by their AI art product.|AI Tools\\nGoogle AI training cluster|Google launched access to their new AI training cluster based on their custom-built TPU architecture, which can be used to train and fine-tune AI models.|AI Infrastructure\\nVertex AI platform upgrades|Google updated its vertex AI platform with upgrades to pom2 enhanced code generation and new search and conversational models.|Google AI\\nSilicon Valley Elite building a city|Silicon Valley elites are building a city from scratch, with the goal of generating thousands of jobs and creating a walkable urban environment.|AI and Urban Development\\nAudiogram|Audiogram launched in beta with the ability to add text to AI-generated images, receiving funding from investors like a16z and index Ventures.|AI Applications\\nRunway's Gen 2|Runway's Gen 2 released a new feature called motion slider, which allows users to control the amount of movement in output videos.|AI Tools\\nApple's hardware for AI|Apple's own silicon, the M1 and M2 chips, are good at running AI models, with the M2 chip being praised for its performance in running large language models.|AI Hardware\\nFuture of AI on mobile phones|Stability AI founder believes that we will see chat GPT level models on mobile phones next year, and gpt4 level models the year after that.|AI on Mobile\\nAI-generated Pixar-like film|X User Jeff synthesized created a two and a half minute long AI-generated pixar-like film called glitch, which looks incredibly realistic.|AI in Entertainment\\nAI and copyright|Regulators are asking for input on how to handle AI-generated content, including questions about how AI models should use copyrighted data, whether AI-generated material can be copyrighted, and how copyright liability will work with AI.|AI and Copyright\",\n",
       " 'errors': [],\n",
       " 'validated_data': {}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try with a website\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
