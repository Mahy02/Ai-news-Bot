{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we should give the model some docs, then let it find out the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/76.5 kB ? eta -:--:--\n",
      "     --------------- ---------------------- 30.7/76.5 kB 660.6 kB/s eta 0:00:01\n",
      "     --------------- ---------------------- 30.7/76.5 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------------------ ------- 61.4/76.5 kB 328.2 kB/s eta 0:00:01\n",
      "     -------------------------------------- 76.5/76.5 kB 385.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: langchain in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (0.0.197)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.7 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (0.0.16)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (1.10.9)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (0.5.8)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (2.0.16)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp->openai) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain basics\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "\n",
    "\n",
    "# Langchain Loaders:\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "\n",
    "# Vector Store and retrievals\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "#import pinecone\n",
    "\n",
    "# Chat Prompt templates for dynamic values\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "# Supporting libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm3 = ChatOpenAI(temperature=0,\n",
    "                  model_name=\"gpt-3.5-turbo-0613\",\n",
    "                  request_timeout = 180\n",
    "                )\n",
    "\n",
    "#llm3= OpenAI(model_name=\"gpt-3.5-turbo-0613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-transcript-api\n",
      "  Using cached youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests->youtube-transcript-api) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests->youtube-transcript-api) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests->youtube-transcript-api) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Installing collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 2 docs. First doc is 1956 tokens\n"
     ]
    }
   ],
   "source": [
    "youtube_loader = YoutubeLoader.from_youtube_url(\"https://youtu.be/5p248yoa3oE?si=TATgA2GMtcQ_MjEA\")\n",
    "transcript = youtube_loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\", \" \"], chunk_size=10000, chunk_overlap=2200)\n",
    "docs = text_splitter.split_documents(transcript)\n",
    "print (f\"You have {len(docs)} docs. First doc is {llm3.get_num_tokens(docs[0].page_content)} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# % START OF EXAMPLES\n",
    "# - Sam's Elisabeth Murdoch Story: Sam got a call from Elizabeth Murdoch when he had just launched The Hustle. She wanted to generate video content.\n",
    "# - Shaan's Rupert Murdoch Story: When Shaan was running Blab he was invited to an event organized by Rupert Murdoch during CES in Las Vegas.\n",
    "# - Revenge Against The Spam Calls: A couple of businesses focused on protecting consumers: RoboCall, TrueCaller, DoNotPay, FitIt\n",
    "# - Wildcard CEOs vs. Prudent CEOs: However, Munger likes to surround himself with prudent CEO's and says he would never hire Musk.\n",
    "# - Chess Business: Priyav, a college student, expressed his doubts on the MFM Facebook group about his Chess training business, mychesstutor.com, making $12.5K MRR with 90 enrolled.\n",
    "# - Restaurant Refiller: An MFM Facebook group member commented on how they pay AirMark $1,000/month for toilet paper and toilet cover refills for their restaurant. Shaan sees an opportunity here for anyone wanting to compete against AirMark.\n",
    "# - Collecting: Shaan shared an idea to build a mobile only marketplace for a collectors' category; similar to what StockX does for premium sneakers.\n",
    "# % END OF EXAMPLES\n",
    "\n",
    "template=\"\"\"\n",
    "You are a helpful assistant that helps retrieve topics talked about in a youtube video transcript\n",
    "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
    "- Topics include:\n",
    "- AI news\n",
    "- GPT Models\n",
    "- Google Models\n",
    "- LLMs\n",
    "- llama Models\n",
    "- AI tutorials\n",
    "- OpenAI\n",
    "- AI for business \n",
    "- AI for education\n",
    "- AI for medicine \n",
    "- AI for art and music\n",
    "- Deep Learning\n",
    "- NLP\n",
    "- Machine Learning\n",
    "- Data science\n",
    "- Opportunities in AI\n",
    "- AI frameworks\n",
    "- Langchain\n",
    "\n",
    "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
    "- Use the same words and terminology that is said in the youtube video\n",
    "- Ignore topics on policy and regulations.\n",
    "- Do not respond with anything outside of the podcast. If you don't see any topics, say, 'No Topics'\n",
    "- Do not respond with numbers, just bullet points\n",
    "- Only pull topics from the transcript. Do not use the examples\n",
    "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
    "- A topic should be substantial, more than just a one-off comment\n",
    "\n",
    "\"\"\"\n",
    "system_message_prompt_map = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"Transcript: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt_map = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_map = ChatPromptTemplate.from_messages(messages=[system_message_prompt_map, human_message_prompt_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % START OF EXAMPLES\n",
    "# - Sam's Elisabeth Murdoch Story: Sam got a call from Elizabeth Murdoch when he had just launched The Hustle. She wanted to generate video content.\n",
    "# - Shaan's Rupert Murdoch Story: When Shaan was running Blab he was invited to an event organized by Rupert Murdoch during CES in Las Vegas.\n",
    "# % END OF EXAMPLES\n",
    "\n",
    "template=\"\"\"\n",
    "You are a helpful assistant that helps retrieve topics talked about in a podcast transcript\n",
    "- You will be given a series of bullet topics of topics vound\n",
    "- Your goal is to exract the topic names and brief 1-sentence description of the topic\n",
    "- Deduplicate any bullet points you see\n",
    "- Only pull topics from the transcript. Do not use the examples.\n",
    "\"\"\"\n",
    "system_message_prompt_map = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"Transcript: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt_map = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt_combine = ChatPromptTemplate.from_messages(messages=[system_message_prompt_map, human_message_prompt_map])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm3,\n",
    "                             chain_type=\"map_reduce\",\n",
    "                             map_prompt=chat_prompt_map,\n",
    "                             combine_prompt=chat_prompt_combine,\n",
    "                              verbose=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics include:\n",
      "- AI news\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- Ignore topics on policy and regulations.\n",
      "- Do not respond with anything outside of the podcast. If you don't see any topics, say, 'No Topics'\n",
      "- Do not respond with numbers, just bullet points\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: should we automate away all the jobs including the fulfilling ones should we allow AI machines to flood the internet with propaganda and fake news should we develop non-human Minds smarter than our own machines that might one day outnumber us or outsmart us do we risk losing control now you might think that sounds like some futuristic script from a Terminator movie but last month some of the most well-known figures who are involved in the development and training of artificial intelligence call for a moratorium until we better understand where we're going an open letter was signed by thousands of entrepreneurs academics and scientists including Elon Musk who wants the training of intelligence haltered for at least six months we're going to dig deep into this over the next 20 minutes or so in the company of two people who know a thing or two about it joining me is the tech investor even burfield the Evan burfield the author of regulatory hacking A playbook for startups he's in Texas I'm Professor Gary Marcus is in Vancouver he's the professor emeritus at New York University and author of rebooting AI Professor let me start with you um clearly with such advances that we're seeing we have to set some guard rails who do you think should be in charge of that uh were we both professors I think that we need Global governance for AI I think that we have a lot of patchworks right now almost balkanized um the worst case from the company's perspective and the world's perspective is if there's 193 jurisdictions each deciding their own rules requiring their own training of these models um each run by governments that don't have much specific expertise in AI so what I called for an economist editorial earlier this weekend in a TED talk earlier this week was to have a global system modeled on something like the international atomic energy Authority where the world comes together and says we have a new threat here but it's really a new set of threats and we need to work together on this so I think the number one thing is it should be Global and the number two thing is it can't be just um policy but it also has to be a research side because we need to invent new tools like we had to invent for fighting spam and cyber warfare and so forth there's so many different threats as you mentioned around misinformation cyber crime and so forth so we need to have a kind of standing organization This Global and well-financed to try to build tools to mitigate those threats so Evan burfield there are many many people who who just want to press the pause button until we work out some of these things but I can already see and I've heard uh the reasons why that probably isn't possible and and that is because not everybody will stop and people are worried about losing competitive Advantage so how do we best go about this yeah I think that's exactly right um you know the the challenge with a moratorium is that it's incredibly hard to enforce um the responsible actors would be more likely to follow it the irresponsible actors wouldn't but that's actually not so much my concern with the moratorium there's absolutely questions we need to be asking about the governance of AI about what industry can do what government can do uh I think the letter did spark a conversation Schumer is working on a new AI bill here in the U.S rumors McCarthy's working on a republican version but what I think is actually much more important is to start to have the conversations about how we prepare our society our economy uh our political system democracy itself for all of the implications of AI that are coming one way or another and I suspect we'll see a year from now we'll go this was less impactful than we thought five years from now it will be an absolute tsunami of upheaval and we have this window right now where we can have this conversation and we can get creative and I think we've got to use it and a moratorium gives us this false sense of security that we have control and can stop it versus figuring out how we ride this tsunami and try to direct it in a much better Direction Professor Marcus did we did we learn anything from the the last technological Advance the advance of the internet of social media are there lessons from that which we let's face it we didn't do very well that are applicable here I think the number one lesson is you don't want to close the Barn Door after the horse has left I think you know we're very late in in figuring out what to do about social media I think we probably handled privacy alone in the wrong way um we wound up with so much polarization and hostility we wound up with misinformation um I think we waited too long to act I think the number one lesson is we should get on it right now and I agree with the other panelists that the moratorium You could argue about the merits whether it was the right thing or the wrong thing it was absolutely the right thing to raise this and get it on everybody's agenda this is not something we want six months from now something we need now so Evan burfield when you talk about a tsunami in five years time what does what does that look like uh look I'm down here in Austin Texas uh at Capitol Factory startup accelerate I've spent the whole day uh you know meeting with startups and there's not a startup right now out there that is not applying these AI generative models these large language models to every interesting problem of the Sun and there's all of the the scary dystopian possibilities that you uh led into this segment with but there's also uh incredible advances in how to make work more fulfilling and more impactful how to apply uh tremendous personalization to Medicine based on our genetics our environment the particular issues we're having how do you make government more responsive and feel more like a concierge to Citizens all of that is also being worked on um and I think figuring out how we put the guard rails in place around some of the scarier things which isn't just about regulating Aya it's about changing our social policy changing our Market policies themselves so that we can mitigate some of that and and direct this into the the much more hopeful and optimistic Direction why why on that point though Evan is it is it imaginable in the current scenario you are around it all the time that a research lab would cross a critical line here without even noticing I I'm I'm personally skeptic you know uh Gary's written some wonderful points about the fact that we are we are very very far I believe from artificial general intelligence and the Terminator scenarios I I think we've got to be very aware of right now is simply that this technology is already right now today at a state if it did not Advance any further where its application is going to profoundly change how we live our lives how we work how we engage with each other in communities how our democracies function uh the impacts on our democracies are going to be felt right in the 2024 political cycle here in the U.S that's what I think we need to be talking about and preparing for the scenarios of AI is like nuclear weapons we have to ban it immediately I think are much less applicable to the the much more realistic uh changes that are already happening around us right now that are going to accelerate miles um you've just come back from Washington and I know that you've been talking to policymakers about the specific issues in fact the reason we're talking about it tonight is because you tweeted no one has a clue I I mean is that is it as blunt as that that nobody really understands it there is practically no work being done on it hi Christian you're you're spot on the three biggest challenges right now with policy makers are one this was completely foreseeable there were some of us in Washington talking about this 10 or 15 years ago policymakers weren't paying attention and most of the think tanks in Washington really failed to start a conversation about the Practical things that needed to be done to prepare for the age of AI so we're behind the ball from a policy making standpoint the second thing I would emphasize what Evan burfield just said there is a wave coming and you can do two things when a wave is coming you can get crushed by it or you can ride the wave and to use another analogy right now the discussion in Washington is about whether to put the genie back in the bottle or not that shouldn't be the discussion it should be what three wishes should we ask the genie and that's the discussion that should be had about how to handle Ai and use it for good purposes and finally the other problem is policy makers are not thinking two steps forward on the chessboard it's AI right now but in in this decade AI is going to be supercharged by other Technologies like Quantum Computing that are going to give machines genuine human-like emotion what are we doing to prepare for that we should be having that conversation now there needs to be institutions in Washington that focus on that so Jack we've had a discussion about that in this country and the UK government has decided that it doesn't need a dedicated UK regulator for AI so who's overseeing it that's a very good question I mean uh I I was on stage last night with the chancellor Jeremy Hunt and I asked him about this you know he's the guy in charge of the UK economy um and he was really quite dismissive he's he in in the sense that he said you know this is something that is going to happen and we have always embraced new technologies in this country and we should do so again uh it's full steam ahead was the phrase that he used um you know he was very very positive he did he did not want to talk about the possibility that people would lose their jobs because of this technology he only saw it as a purely positive thing and he was not keen to talk about the way it should be regulated now you know I'm no expert on this still if I'm a politics guy but what I do know is that is how Westminster\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve topics talked about in a youtube video transcript\n",
      "- Your goal is to extract the topic names and brief 1-sentence description of the topic\n",
      "- Topics include:\n",
      "- AI news\n",
      "- GPT Models\n",
      "- Google Models\n",
      "- LLMs\n",
      "- llama Models\n",
      "- AI tutorials\n",
      "- OpenAI\n",
      "- AI for business \n",
      "- AI for education\n",
      "- AI for medicine \n",
      "- AI for art and music\n",
      "- Deep Learning\n",
      "- NLP\n",
      "- Machine Learning\n",
      "- Data science\n",
      "- Opportunities in AI\n",
      "- AI frameworks\n",
      "- Langchain\n",
      "\n",
      "- Provide a brief description of the topics after the topic name. Example: 'Topic: Brief Description'\n",
      "- Use the same words and terminology that is said in the youtube video\n",
      "- Ignore topics on policy and regulations.\n",
      "- Do not respond with anything outside of the podcast. If you don't see any topics, say, 'No Topics'\n",
      "- Do not respond with numbers, just bullet points\n",
      "- Only pull topics from the transcript. Do not use the examples\n",
      "- Make your titles descriptive but concise. Example: 'Shaan's Experience at Twitch' should be 'Shaan's Interesting Projects At Twitch'\n",
      "- A topic should be substantial, more than just a one-off comment\n",
      "\n",
      "\n",
      "Human: Transcript: in Washington talking about this 10 or 15 years ago policymakers weren't paying attention and most of the think tanks in Washington really failed to start a conversation about the Practical things that needed to be done to prepare for the age of AI so we're behind the ball from a policy making standpoint the second thing I would emphasize what Evan burfield just said there is a wave coming and you can do two things when a wave is coming you can get crushed by it or you can ride the wave and to use another analogy right now the discussion in Washington is about whether to put the genie back in the bottle or not that shouldn't be the discussion it should be what three wishes should we ask the genie and that's the discussion that should be had about how to handle Ai and use it for good purposes and finally the other problem is policy makers are not thinking two steps forward on the chessboard it's AI right now but in in this decade AI is going to be supercharged by other Technologies like Quantum Computing that are going to give machines genuine human-like emotion what are we doing to prepare for that we should be having that conversation now there needs to be institutions in Washington that focus on that so Jack we've had a discussion about that in this country and the UK government has decided that it doesn't need a dedicated UK regulator for AI so who's overseeing it that's a very good question I mean uh I I was on stage last night with the chancellor Jeremy Hunt and I asked him about this you know he's the guy in charge of the UK economy um and he was really quite dismissive he's he in in the sense that he said you know this is something that is going to happen and we have always embraced new technologies in this country and we should do so again uh it's full steam ahead was the phrase that he used um you know he was very very positive he did he did not want to talk about the possibility that people would lose their jobs because of this technology he only saw it as a purely positive thing and he was not keen to talk about the way it should be regulated now you know I'm no expert on this still if I'm a politics guy but what I do know is that is how Westminster works and how um political systems work and I can tell you now and you'll know this Christian there is no way our political system is set up to deal with this challenge absolutely no chance the speed at which decisions are made in Westminster and I suspect in other major political centers is far too slow to cope with the pace at which this technology is coming the policy makers do not understand it at all this is just something that is going to wash over us and we're going to have to cross our fingers you know the UK government put out a white paper which is what they call their draft strategy on AI the other day I mean just the very name of it white paper tells you how old school this is yeah you know it's out of date already and that thing took you know years for them to put together um we just don't have the sort of nimble small system smart thinking people set up to deal with this and I'd be very surprised if that's different in the US or indeed in many of the other big Power centers well they clearly don't understand it Professor Marcus do they call you in to try and get you to explain it to them that I was talking to people in the U.S and Canadian government yesterday I've been called a lot lately um I think there is an awareness that people don't quite know what to do and they are increasingly turning to me um and also turning to all of my you know academic colleagues and so forth so I think that there's at least a recognition and people know what they don't know I do think that the UK white paper saying that you won't have a central office of AI is certainly for all the reasons that were kind of implicitly just said which is um the government is going to be ill-equipped to deal with the speed of this and if you just leave it to 20 different Regulatory Agencies Each of which don't have expertise you're asking for trouble you're asking for a lack of coordination and it's just not realistic that all of those agencies are going to be up on things so there needs to be I think at least some Central oversight I think the United States should consider a cabinet level AI officer and you should consider something comparable um you need some people maybe like a G7 then we have a G7 meeting of foreign ministers we need a G7 meeting of of IAAI ministers is that is that effectively what you're saying well I mean I'm calling for something similar which is a global organization uh kind of like the IMF or an international atomic energy agency um where you have a lot of experts you have a lot of people in government you have a lot of people in uh the companies and yeah you have regular meetings you're like well this week the new thing is this thing called this is a real example called Auto gbt where you have ai's training other AIS what do we do about that how big a threat is it is it a small threat big threat like if you have a research arm then you can say let's do some experiments here and try to figure out what the limits are right now instead you have like 193 countries maybe some of them have read the news about this major news Discovery some of them haven't even aren't even aware of it and there's like no coordination here that just can't be the right way you're nodding Evan because this is the key issue it's miles as miles discussed it's not human competitive intelligence it's it's what happens after AI gets smarter than humor intelligence right amazing but you know I I can't go to a conference I I actually live in Washington DC most the time I can't go to a dinner or a conference a meeting without the word I being discussed and they're all talking about chat GPT and Gary's right is that even Auto gppt there was a an experiment run last week called chaos GPT where they took a neutered version of Auto GPT and told it to go out and figure out the most efficient way to destroy Humanity it was a it was sort of a test and it's set to work doing it there's there's a lot of this stuff is moving incredibly fast and figuring out how you can educate policy makers about how to mitigate regulate bring transparency to some of those threats while not preventing what can be breathtaking advances in um how we live our lives in much more fulfilling and purposeful ways and Society I think that's that's a lot of the trick here to Echo Jack's point though about white papers and the way you know government moves I I tend to agree you know miles may be more optimistic than I am but I tend to agree I think a lot of the big changes that are going to need to happen probably won't happen until uh there's some sort of provoking event some sort of Crisis I don't think that though prevents us from starting to have the conversations at least the Way Washington tends to work at least you want to have the the policy container the framework the ideas ready some sort of consensus being built so that when the opportunity presents itself kind of like a a VC who sees a great startup right when the opportunity presents itself you're ready to jump on it you're ready to move forward and I think that that has to be happening right now go ahead the opportunity that I see right now is to build some Global governance I think you have the governments are afraid of the technology companies the technology companies are afraid the governments are going to shut them down as they did in Italy and this means everybody has some incentive to go to the table that's rare and I think we should be seizing that opportunity right now to try to do something coherent that is dynamic enough to cope with the speed of the change to take advantage of the good things and and to avoid the bad things but we need that coordination now and we can't just leave this to the usual mechanisms it's just too slow miles one of the more worrying things that you said was that speaking McCarthy was looking at an AI for for republicans and you know one of the experiences we have of recent years is that the Russians were able to interfere in a democracy and who knows arguably it's been debated whether they were able to change some of the results through what they were putting onto the internet I mean we're into a whole new ball game for democracy if AI can put out misinformation and propaganda it's not if it's how much and when it's going to happen probably in West 2024 election wow yeah there's no question I mean this this coming election cycle in the United States it's a big concern for election security authorities it should be but I yeah I got to go back to what the other panelists said in order to respond to it effectively we've got to start with education and right now I mean I've tried to brief policy makers on this it's like explaining particle physics to a chocolate chip cookie I mean there's just not recognition about what's happening if I was President Joe Biden right now I will put I would put the entire cabinet on Air Force One I would fly them to Silicon Valley and we would spend the week educate educating them about what's happening because there aren't just these security implications for the elections as Evan notes there's also really positive implications I mean there's the ability to address major health care problems hunger homelessness and to do it in real time and we are missing some opportunities by policy makers not being educated on the subject but of course security has to come first and in order to protect elections or anything else it's got to start with you know policy makers becoming technologists being educated fascinating conversation we're gonna have to leave it there Evan burfield Gary Marcus thank you very much indeed for joining us\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are a helpful assistant that helps retrieve topics talked about in a podcast transcript\n",
      "- You will be given a series of bullet topics of topics vound\n",
      "- Your goal is to exract the topic names and brief 1-sentence description of the topic\n",
      "- Deduplicate any bullet points you see\n",
      "- Only pull topics from the transcript. Do not use the examples.\n",
      "\n",
      "Human: Transcript: Topics:\n",
      "- AI governance: The need for global governance and collaboration to address the challenges and threats posed by AI.\n",
      "- Implications of AI: The potential impact of AI on society, economy, democracy, and politics.\n",
      "- AI applications: The use of AI in various fields such as medicine, government, and personalized services.\n",
      "- AI advancements: The current state of AI technology and its potential for further development.\n",
      "- Policy and regulation: The need for proactive policy-making and regulation to address the ethical and societal implications of AI.\n",
      "- AI and job displacement: The concern over the automation of jobs and the potential loss of employment due to AI.\n",
      "- AI and misinformation: The risks associated with AI-generated propaganda and fake news.\n",
      "- AI and privacy: The need to address privacy concerns and protect personal data in the age of AI.\n",
      "- AI and social impact: The potential positive and negative effects of AI on society and communities.\n",
      "- AI and education: The role of AI in transforming education and learning.\n",
      "- AI and politics: The impact of AI on political systems and the need for policymakers to understand and address its implications.\n",
      "- AI and economy: The potential economic benefits and challenges of AI.\n",
      "- AI and research: The importance of ongoing research and development to address the threats and challenges posed by AI.\n",
      "- AI and technology convergence: The integration of AI with other emerging technologies like quantum computing.\n",
      "- AI and job creation: The potential for AI to create new job opportunities and enhance work experiences.\n",
      "- AI and market policies: The need to adapt market policies to mitigate the negative impacts of AI and direct its development in a positive direction.\n",
      "- AI and public perception: The need to educate the public about AI and its implications to foster informed discussions and decision-making.\n",
      "\n",
      "Topics:\n",
      "- Policy making and preparation for the age of AI\n",
      "- Wave of AI and the need to ride it\n",
      "- Discussion on handling AI for good purposes\n",
      "- Lack of forward-thinking in policy making\n",
      "- Need for institutions focusing on AI in Washington\n",
      "- UK government's dismissal of the need for a dedicated AI regulator\n",
      "- Inadequacy of political systems to deal with AI challenges\n",
      "- Lack of understanding of AI by policy makers\n",
      "- Call for global oversight and coordination on AI\n",
      "- Need for a central office of AI or cabinet-level AI officer\n",
      "- Lack of coordination and expertise among regulatory agencies\n",
      "- Call for a global organization similar to the IMF or IAEA for AI\n",
      "- Concerns about AI's impact on democracy, including misinformation and propaganda\n",
      "- Need for education and awareness among policy makers\n",
      "- Positive implications of AI in addressing healthcare, hunger, and homelessness\n",
      "- Importance of policy makers becoming technologists and being educated on AI.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "topics_found = chain.run({\"input_documents\": docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "1. AI governance: The need for global governance and collaboration to address the challenges and threats posed by AI.\n",
      "2. Implications of AI: The potential impact of AI on society, economy, democracy, and politics.\n",
      "3. AI applications: The use of AI in various fields such as medicine, government, and personalized services.\n",
      "4. AI advancements: The current state of AI technology and its potential for further development.\n",
      "5. Policy and regulation: The need for proactive policy-making and regulation to address the ethical and societal implications of AI.\n",
      "6. AI and job displacement: The concern over the automation of jobs and the potential loss of employment due to AI.\n",
      "7. AI and misinformation: The risks associated with AI-generated propaganda and fake news.\n",
      "8. AI and privacy: The need to address privacy concerns and protect personal data in the age of AI.\n",
      "9. AI and social impact: The potential positive and negative effects of AI on society and communities.\n",
      "10. AI and education: The role of AI in transforming education and learning.\n",
      "11. AI and politics: The impact of AI on political systems and the need for policymakers to understand and address its implications.\n",
      "12. AI and economy: The potential economic benefits and challenges of AI.\n",
      "13. AI and research: The importance of ongoing research and development to address the threats and challenges posed by AI.\n",
      "14. AI and technology convergence: The integration of AI with other emerging technologies like quantum computing.\n",
      "15. AI and job creation: The potential for AI to create new job opportunities and enhance work experiences.\n",
      "16. AI and market policies: The need to adapt market policies to mitigate the negative impacts of AI and direct its development in a positive direction.\n",
      "17. AI and public perception: The need to educate the public about AI and its implications to foster informed discussions and decision-making.\n",
      "18. Policy making and preparation for the age of AI: Discussion on handling AI for good purposes and the lack of forward-thinking in policy making.\n",
      "19. Need for institutions focusing on AI in Washington: UK government's dismissal of the need for a dedicated AI regulator and the inadequacy of political systems to deal with AI challenges.\n",
      "20. Lack of understanding of AI by policy makers: Call for global oversight and coordination on AI and the need for a central office of AI or cabinet-level AI officer.\n",
      "21. Lack of coordination and expertise among regulatory agencies: Call for a global organization similar to the IMF or IAEA for AI.\n",
      "22. Concerns about AI's impact on democracy, including misinformation and propaganda.\n",
      "23. Need for education and awareness among policy makers: Positive implications of AI in addressing healthcare, hunger, and homelessness.\n",
      "24. Importance of policy makers becoming technologists and being educated on AI.\n"
     ]
    }
   ],
   "source": [
    "print(topics_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kor\n",
      "  Downloading kor-0.13.0-py3-none-any.whl (29 kB)\n",
      "Collecting langchain>=0.0.205\n",
      "  Downloading langchain-0.0.283-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/1.6 MB 653.6 kB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.1/1.6 MB 762.6 kB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.1/1.6 MB 744.7 kB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.1/1.6 MB 552.2 kB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.1/1.6 MB 566.5 kB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.2/1.6 MB 551.6 kB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.2/1.6 MB 588.9 kB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 0.2/1.6 MB 597.3 kB/s eta 0:00:03\n",
      "     ------ --------------------------------- 0.3/1.6 MB 582.4 kB/s eta 0:00:03\n",
      "     ------ --------------------------------- 0.3/1.6 MB 570.1 kB/s eta 0:00:03\n",
      "     ------- -------------------------------- 0.3/1.6 MB 615.2 kB/s eta 0:00:03\n",
      "     -------- ------------------------------- 0.4/1.6 MB 618.4 kB/s eta 0:00:03\n",
      "     --------- ------------------------------ 0.4/1.6 MB 606.2 kB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 0.4/1.6 MB 623.4 kB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 0.4/1.6 MB 625.1 kB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.5/1.6 MB 614.4 kB/s eta 0:00:02\n",
      "     ------------ --------------------------- 0.5/1.6 MB 642.4 kB/s eta 0:00:02\n",
      "     ------------- -------------------------- 0.6/1.6 MB 643.0 kB/s eta 0:00:02\n",
      "     -------------- ------------------------- 0.6/1.6 MB 643.6 kB/s eta 0:00:02\n",
      "     --------------- ------------------------ 0.6/1.6 MB 655.0 kB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 0.7/1.6 MB 675.7 kB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 0.7/1.6 MB 694.6 kB/s eta 0:00:02\n",
      "     ------------------- -------------------- 0.8/1.6 MB 721.3 kB/s eta 0:00:02\n",
      "     -------------------- ------------------- 0.8/1.6 MB 737.3 kB/s eta 0:00:02\n",
      "     --------------------- ------------------ 0.9/1.6 MB 751.4 kB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 0.9/1.6 MB 764.4 kB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 1.0/1.6 MB 760.3 kB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.0/1.6 MB 779.9 kB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.1/1.6 MB 783.1 kB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.1/1.6 MB 786.0 kB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 1.2/1.6 MB 795.8 kB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.2/1.6 MB 805.5 kB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.3/1.6 MB 820.8 kB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.3/1.6 MB 828.7 kB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.4/1.6 MB 836.2 kB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.4/1.6 MB 849.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.5/1.6 MB 867.6 kB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.6/1.6 MB 873.4 kB/s eta 0:00:01\n",
      "     ---------------------------------------  1.6/1.6 MB 884.6 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 881.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.5.3 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from kor) (1.5.3)\n",
      "Collecting openai<0.28,>=0.27\n",
      "  Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 41.0/76.5 kB 960.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 76.5/76.5 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (8.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (3.8.4)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (2.8.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (1.10.9)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (4.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (6.0)\n",
      "Collecting langsmith<0.1.0,>=0.0.21\n",
      "  Downloading langsmith-0.0.33-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (2.0.16)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (0.5.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (2.31.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain>=0.0.205->kor) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai<0.28,>=0.27->kor) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pandas<2.0.0,>=1.5.3->kor) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pandas<2.0.0,>=1.5.3->kor) (2023.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (3.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.205->kor) (1.9.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (3.19.0)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (0.9.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (1.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pydantic<3,>=1->langchain>=0.0.205->kor) (4.6.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.5.3->kor) (1.16.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.205->kor) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.205->kor) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.205->kor) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.205->kor) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tqdm->openai<0.28,>=0.27->kor) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mahinour elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.205->kor) (1.0.0)\n",
      "Installing collected packages: langsmith, openai, langchain, kor\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.197\n",
      "    Uninstalling langchain-0.0.197:\n",
      "      Successfully uninstalled langchain-0.0.197\n",
      "Successfully installed kor-0.13.0 langchain-0.0.283 langsmith-0.0.33 openai-0.27.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        # The title of the topic\n",
    "        \"topic_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The title of the topic listed\"\n",
    "        },\n",
    "        # The description\n",
    "        \"description\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The description of the topic listed\"\n",
    "        },\n",
    "        \"tag\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The type of content being described\",\n",
    "            \"enum\" : ['AI Models & LLMs', 'AI job opportunities', 'AI frameworks', 'Deep Learning', 'Machine Learning', 'Data science']\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"topic\", \"description\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Object(\n",
    "    id=\"person\",\n",
    "    description={\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The description of the topic listed\"\n",
    "        },\n",
    "    \n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"first_name\",\n",
    "            description=\"The first name of a person.\",\n",
    "        )\n",
    "    ],\n",
    "    many=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "node must be an Object got <class 'langchain.chat_models.openai.ChatOpenAI'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chain \u001b[39m=\u001b[39m create_extraction_chain(schema, llm3)\n\u001b[0;32m      2\u001b[0m \u001b[39m#chain = create_extraction_chain(llm3, schema)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mahinour Elsarky\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\kor\\extraction\\api.py:102\u001b[0m, in \u001b[0;36mcreate_extraction_chain\u001b[1;34m(llm, node, encoder_or_encoder_class, type_descriptor, validator, input_formatter, instruction_template, verbose, **encoder_kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create an extraction chain.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m                                    input_formatter=\"triple_quotes\")\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(node, Object):\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnode must be an Object got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(node)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m encoder \u001b[39m=\u001b[39m initialize_encoder(encoder_or_encoder_class, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    104\u001b[0m type_descriptor_to_use \u001b[39m=\u001b[39m initialize_type_descriptors(type_descriptor)\n",
      "\u001b[1;31mValueError\u001b[0m: node must be an Object got <class 'langchain.chat_models.openai.ChatOpenAI'>"
     ]
    }
   ],
   "source": [
    "#chain = create_extraction_chain(schema, llm3)\n",
    "chain = create_extraction_chain(llm3, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_structured = chain.run(topics_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_structured"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
